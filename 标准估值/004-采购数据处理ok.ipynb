{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T01:34:34.924169Z",
     "start_time": "2020-03-24T01:34:33.544354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAYU_HOME : /home/souche/projects/datacenter-etl-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/souche/projects/calculation/py3dev_new/lib/python3.5/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-05 09:38:47,090] {driver:120} INFO - Generating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "[2020-11-05 09:38:47,117] {driver:120} INFO - Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "[2020-11-05 09:38:48,561] {<ipython-input-1-b6909f377136>:54} INFO - 当前日期: 2020-11-05\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import logging\n",
    "import datetime\n",
    "from logging.handlers import TimedRotatingFileHandler\n",
    "from logging.handlers import RotatingFileHandler\n",
    "from sklearn.externals import joblib\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "from dayu.hooks.oss_hook import OSSHook\n",
    "\n",
    "from dayu.hooks.hive_server_hook import HiveServerHook\n",
    "from dayu.hooks.hive_cli_hook import HiveCliHook\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from fastFM import sgd\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csc_matrix\n",
    "import time\n",
    "from sklearn.metrics import auc,accuracy_score,roc_curve,roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix,recall_score\n",
    "from sklearn import  metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def split_table_name(datain):\n",
    "    new_cols = []\n",
    "    for column in datain.columns:\n",
    "        if(len(column.split('.'))<2):\n",
    "            return datain\n",
    "        tb_name, col_name = column.split('.')\n",
    "        new_cols.append((column, col_name))\n",
    "    datain = datain.rename(columns=dict(new_cols))\n",
    "    return datain\n",
    "\n",
    "def read_from_hive2(output_file_name,insql,dtype):\n",
    "    filename = output_file_name\n",
    "    filepath = curr_dir+filename\n",
    "    hive = HiveServerHook(\"warehouse_hive\")\n",
    "    hive.to_csv(insql,filepath , delimiter=',',lineterminator='\\n', output_header=True)\n",
    "    outdata = pd.read_csv(filepath, header=0,dtype=dtype)\n",
    "    # 去除列名中带有的表名\n",
    "    outdata = split_table_name(outdata)\n",
    "    return outdata\n",
    "\n",
    "curr_date = str(datetime.datetime.now())[0:10]\n",
    "logging.info('当前日期: %s'%(curr_date))\n",
    "curr_dir = '/home/souche/qiongjiu/hgc/'\n",
    "curr_date=str(datetime.datetime.now())[0:10]\n",
    "hive_cli = HiveCliHook(\"warehouse_hive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T01:36:55.176142Z",
     "start_time": "2020-03-24T01:35:42.085535Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-05 09:38:48,638] {hiveserver2:138} INFO - Using database default as default\n",
      "[2020-11-05 09:38:48,808] {hive_server_hook:112} INFO - Running query: \n",
      "SELECT purchase_order_id as car_id,\n",
      "       brand_code,\n",
      "       brand_name,\n",
      "       series_code,\n",
      "       series_name,\n",
      "       model_code,\n",
      "       model_name,\n",
      "       cast(mileage/10000 AS DECIMAL(10,2)) AS mileage_std,\n",
      "       color AS color_name,\n",
      "       first_license_date as first_license_plate_date,\n",
      "       province_name,\n",
      "       city_name,\n",
      "       cast(purchase_price/10000 AS DECIMAL(10,2)) AS purchase_price,\n",
      "       date(pay_time) as order_create_time,\n",
      "       age AS license_month,\n",
      "       residual,\n",
      "       -- 需要按照当年情况来修改\n",
      "       datediff(\"2020-12-31 00:00:00\", pay_time) AS days,\n",
      "       cast(year(first_license_date) AS INT) AS license_year\n",
      "FROM db_data.mid_car_dfc_purchase_order_flag_b\n",
      "WHERE flag = 0 \n",
      "and pay_time is not null\n",
      " -- 确认选取建模时间\n",
      "and pay_time<=\"2020-11-02\"\n",
      "and province_name is not null\n",
      "and city_name is not null\n",
      "\n",
      "[2020-11-05 09:38:49,863] {hive_server_hook:162} INFO - Written 10000 rows so far.\n",
      "[2020-11-05 09:38:50,675] {hive_server_hook:162} INFO - Written 20000 rows so far.\n",
      "[2020-11-05 09:38:51,472] {hive_server_hook:162} INFO - Written 30000 rows so far.\n",
      "[2020-11-05 09:38:52,275] {hive_server_hook:162} INFO - Written 40000 rows so far.\n",
      "[2020-11-05 09:38:53,013] {hive_server_hook:162} INFO - Written 50000 rows so far.\n",
      "[2020-11-05 09:38:53,821] {hive_server_hook:162} INFO - Written 60000 rows so far.\n",
      "[2020-11-05 09:38:54,615] {hive_server_hook:162} INFO - Written 70000 rows so far.\n",
      "[2020-11-05 09:38:55,418] {hive_server_hook:162} INFO - Written 80000 rows so far.\n",
      "[2020-11-05 09:38:56,176] {hive_server_hook:162} INFO - Written 90000 rows so far.\n",
      "[2020-11-05 09:38:56,995] {hive_server_hook:162} INFO - Written 100000 rows so far.\n",
      "[2020-11-05 09:38:57,803] {hive_server_hook:162} INFO - Written 110000 rows so far.\n",
      "[2020-11-05 09:38:58,593] {hive_server_hook:162} INFO - Written 120000 rows so far.\n",
      "[2020-11-05 09:38:59,349] {hive_server_hook:162} INFO - Written 130000 rows so far.\n",
      "[2020-11-05 09:39:00,149] {hive_server_hook:162} INFO - Written 140000 rows so far.\n",
      "[2020-11-05 09:39:00,950] {hive_server_hook:162} INFO - Written 150000 rows so far.\n",
      "[2020-11-05 09:39:01,754] {hive_server_hook:162} INFO - Written 160000 rows so far.\n",
      "[2020-11-05 09:39:02,555] {hive_server_hook:162} INFO - Written 170000 rows so far.\n",
      "[2020-11-05 09:39:03,293] {hive_server_hook:162} INFO - Written 180000 rows so far.\n",
      "[2020-11-05 09:39:04,122] {hive_server_hook:162} INFO - Written 190000 rows so far.\n",
      "[2020-11-05 09:39:04,922] {hive_server_hook:162} INFO - Written 200000 rows so far.\n",
      "[2020-11-05 09:39:05,714] {hive_server_hook:162} INFO - Written 210000 rows so far.\n",
      "[2020-11-05 09:39:06,451] {hive_server_hook:162} INFO - Written 220000 rows so far.\n",
      "[2020-11-05 09:39:07,257] {hive_server_hook:162} INFO - Written 230000 rows so far.\n",
      "[2020-11-05 09:39:08,063] {hive_server_hook:162} INFO - Written 240000 rows so far.\n",
      "[2020-11-05 09:39:08,850] {hive_server_hook:162} INFO - Written 250000 rows so far.\n",
      "[2020-11-05 09:39:09,621] {hive_server_hook:162} INFO - Written 260000 rows so far.\n",
      "[2020-11-05 09:39:10,413] {hive_server_hook:162} INFO - Written 270000 rows so far.\n",
      "[2020-11-05 09:39:11,256] {hive_server_hook:162} INFO - Written 280000 rows so far.\n",
      "[2020-11-05 09:39:12,058] {hive_server_hook:162} INFO - Written 290000 rows so far.\n",
      "[2020-11-05 09:39:12,813] {hive_server_hook:162} INFO - Written 300000 rows so far.\n",
      "[2020-11-05 09:39:13,609] {hive_server_hook:162} INFO - Written 310000 rows so far.\n",
      "[2020-11-05 09:39:14,410] {hive_server_hook:162} INFO - Written 320000 rows so far.\n",
      "[2020-11-05 09:39:15,200] {hive_server_hook:162} INFO - Written 330000 rows so far.\n",
      "[2020-11-05 09:39:16,039] {hive_server_hook:162} INFO - Written 340000 rows so far.\n",
      "[2020-11-05 09:39:16,786] {hive_server_hook:162} INFO - Written 350000 rows so far.\n",
      "[2020-11-05 09:39:17,585] {hive_server_hook:162} INFO - Written 360000 rows so far.\n",
      "[2020-11-05 09:39:18,371] {hive_server_hook:162} INFO - Written 370000 rows so far.\n",
      "[2020-11-05 09:39:19,175] {hive_server_hook:162} INFO - Written 380000 rows so far.\n",
      "[2020-11-05 09:39:19,914] {hive_server_hook:162} INFO - Written 390000 rows so far.\n",
      "[2020-11-05 09:39:20,703] {hive_server_hook:162} INFO - Written 400000 rows so far.\n",
      "[2020-11-05 09:39:21,490] {hive_server_hook:162} INFO - Written 410000 rows so far.\n",
      "[2020-11-05 09:39:22,281] {hive_server_hook:162} INFO - Written 420000 rows so far.\n",
      "[2020-11-05 09:39:23,030] {hive_server_hook:162} INFO - Written 430000 rows so far.\n",
      "[2020-11-05 09:39:23,824] {hive_server_hook:162} INFO - Written 440000 rows so far.\n",
      "[2020-11-05 09:39:24,635] {hive_server_hook:162} INFO - Written 450000 rows so far.\n",
      "[2020-11-05 09:39:25,437] {hive_server_hook:162} INFO - Written 460000 rows so far.\n",
      "[2020-11-05 09:39:26,205] {hive_server_hook:162} INFO - Written 470000 rows so far.\n",
      "[2020-11-05 09:39:27,002] {hive_server_hook:162} INFO - Written 480000 rows so far.\n",
      "[2020-11-05 09:39:27,798] {hive_server_hook:162} INFO - Written 490000 rows so far.\n",
      "[2020-11-05 09:39:28,591] {hive_server_hook:162} INFO - Written 500000 rows so far.\n",
      "[2020-11-05 09:39:29,410] {hive_server_hook:162} INFO - Written 510000 rows so far.\n",
      "[2020-11-05 09:39:30,159] {hive_server_hook:162} INFO - Written 520000 rows so far.\n",
      "[2020-11-05 09:39:30,962] {hive_server_hook:162} INFO - Written 530000 rows so far.\n",
      "[2020-11-05 09:39:31,757] {hive_server_hook:162} INFO - Written 540000 rows so far.\n",
      "[2020-11-05 09:39:32,591] {hive_server_hook:162} INFO - Written 550000 rows so far.\n",
      "[2020-11-05 09:39:33,322] {hive_server_hook:162} INFO - Written 560000 rows so far.\n",
      "[2020-11-05 09:39:34,199] {hive_server_hook:162} INFO - Written 570000 rows so far.\n",
      "[2020-11-05 09:39:34,989] {hive_server_hook:162} INFO - Written 580000 rows so far.\n",
      "[2020-11-05 09:39:35,827] {hive_server_hook:162} INFO - Written 590000 rows so far.\n",
      "[2020-11-05 09:39:36,579] {hive_server_hook:162} INFO - Written 600000 rows so far.\n",
      "[2020-11-05 09:39:37,387] {hive_server_hook:162} INFO - Written 610000 rows so far.\n",
      "[2020-11-05 09:39:38,192] {hive_server_hook:162} INFO - Written 620000 rows so far.\n",
      "[2020-11-05 09:39:39,018] {hive_server_hook:162} INFO - Written 630000 rows so far.\n",
      "[2020-11-05 09:39:39,762] {hive_server_hook:162} INFO - Written 640000 rows so far.\n",
      "[2020-11-05 09:39:40,598] {hive_server_hook:162} INFO - Written 650000 rows so far.\n",
      "[2020-11-05 09:39:41,490] {hive_server_hook:162} INFO - Written 660000 rows so far.\n",
      "[2020-11-05 09:39:42,326] {hive_server_hook:162} INFO - Written 670000 rows so far.\n",
      "[2020-11-05 09:39:43,168] {hive_server_hook:162} INFO - Written 680000 rows so far.\n",
      "[2020-11-05 09:39:43,901] {hive_server_hook:162} INFO - Written 690000 rows so far.\n",
      "[2020-11-05 09:39:44,699] {hive_server_hook:162} INFO - Written 700000 rows so far.\n",
      "[2020-11-05 09:39:45,493] {hive_server_hook:162} INFO - Written 710000 rows so far.\n",
      "[2020-11-05 09:39:46,288] {hive_server_hook:162} INFO - Written 720000 rows so far.\n",
      "[2020-11-05 09:39:47,024] {hive_server_hook:162} INFO - Written 730000 rows so far.\n",
      "[2020-11-05 09:39:47,803] {hive_server_hook:162} INFO - Written 740000 rows so far.\n",
      "[2020-11-05 09:39:48,591] {hive_server_hook:162} INFO - Written 750000 rows so far.\n",
      "[2020-11-05 09:39:49,373] {hive_server_hook:162} INFO - Written 760000 rows so far.\n",
      "[2020-11-05 09:39:50,098] {hive_server_hook:162} INFO - Written 770000 rows so far.\n",
      "[2020-11-05 09:39:50,895] {hive_server_hook:162} INFO - Written 780000 rows so far.\n",
      "[2020-11-05 09:39:51,678] {hive_server_hook:162} INFO - Written 790000 rows so far.\n",
      "[2020-11-05 09:39:52,464] {hive_server_hook:162} INFO - Written 800000 rows so far.\n",
      "[2020-11-05 09:39:53,251] {hive_server_hook:162} INFO - Written 810000 rows so far.\n",
      "[2020-11-05 09:39:53,975] {hive_server_hook:162} INFO - Written 820000 rows so far.\n",
      "[2020-11-05 09:39:54,788] {hive_server_hook:162} INFO - Written 830000 rows so far.\n",
      "[2020-11-05 09:39:55,612] {hive_server_hook:162} INFO - Written 840000 rows so far.\n",
      "[2020-11-05 09:39:56,394] {hive_server_hook:162} INFO - Written 850000 rows so far.\n",
      "[2020-11-05 09:39:57,130] {hive_server_hook:162} INFO - Written 860000 rows so far.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-05 09:39:57,933] {hive_server_hook:162} INFO - Written 870000 rows so far.\n",
      "[2020-11-05 09:39:58,716] {hive_server_hook:162} INFO - Written 880000 rows so far.\n",
      "[2020-11-05 09:39:59,501] {hive_server_hook:162} INFO - Written 890000 rows so far.\n",
      "[2020-11-05 09:40:00,237] {hive_server_hook:162} INFO - Written 900000 rows so far.\n",
      "[2020-11-05 09:40:01,044] {hive_server_hook:162} INFO - Written 910000 rows so far.\n",
      "[2020-11-05 09:40:01,824] {hive_server_hook:162} INFO - Written 920000 rows so far.\n",
      "[2020-11-05 09:40:02,601] {hive_server_hook:162} INFO - Written 930000 rows so far.\n",
      "[2020-11-05 09:40:03,331] {hive_server_hook:162} INFO - Written 940000 rows so far.\n",
      "[2020-11-05 09:40:04,162] {hive_server_hook:162} INFO - Written 950000 rows so far.\n",
      "[2020-11-05 09:40:04,940] {hive_server_hook:162} INFO - Written 960000 rows so far.\n",
      "[2020-11-05 09:40:05,722] {hive_server_hook:162} INFO - Written 970000 rows so far.\n",
      "[2020-11-05 09:40:06,500] {hive_server_hook:162} INFO - Written 980000 rows so far.\n",
      "[2020-11-05 09:40:07,219] {hive_server_hook:162} INFO - Written 990000 rows so far.\n",
      "[2020-11-05 09:40:07,993] {hive_server_hook:162} INFO - Written 1000000 rows so far.\n",
      "[2020-11-05 09:40:08,772] {hive_server_hook:162} INFO - Written 1010000 rows so far.\n",
      "[2020-11-05 09:40:09,575] {hive_server_hook:162} INFO - Written 1020000 rows so far.\n",
      "[2020-11-05 09:40:10,323] {hive_server_hook:162} INFO - Written 1030000 rows so far.\n",
      "[2020-11-05 09:40:11,138] {hive_server_hook:162} INFO - Written 1040000 rows so far.\n",
      "[2020-11-05 09:40:12,003] {hive_server_hook:162} INFO - Written 1050000 rows so far.\n",
      "[2020-11-05 09:40:12,810] {hive_server_hook:162} INFO - Written 1060000 rows so far.\n",
      "[2020-11-05 09:40:13,568] {hive_server_hook:162} INFO - Written 1070000 rows so far.\n",
      "[2020-11-05 09:40:14,373] {hive_server_hook:162} INFO - Written 1080000 rows so far.\n",
      "[2020-11-05 09:40:15,159] {hive_server_hook:162} INFO - Written 1090000 rows so far.\n",
      "[2020-11-05 09:40:15,949] {hive_server_hook:162} INFO - Written 1100000 rows so far.\n",
      "[2020-11-05 09:40:16,679] {hive_server_hook:162} INFO - Written 1110000 rows so far.\n",
      "[2020-11-05 09:40:17,474] {hive_server_hook:162} INFO - Written 1120000 rows so far.\n",
      "[2020-11-05 09:40:18,266] {hive_server_hook:162} INFO - Written 1130000 rows so far.\n",
      "[2020-11-05 09:40:19,058] {hive_server_hook:162} INFO - Written 1140000 rows so far.\n",
      "[2020-11-05 09:40:19,862] {hive_server_hook:162} INFO - Written 1150000 rows so far.\n",
      "[2020-11-05 09:40:20,608] {hive_server_hook:162} INFO - Written 1160000 rows so far.\n",
      "[2020-11-05 09:40:21,393] {hive_server_hook:162} INFO - Written 1170000 rows so far.\n",
      "[2020-11-05 09:40:22,171] {hive_server_hook:162} INFO - Written 1180000 rows so far.\n",
      "[2020-11-05 09:40:22,973] {hive_server_hook:162} INFO - Written 1190000 rows so far.\n",
      "[2020-11-05 09:40:23,716] {hive_server_hook:162} INFO - Written 1200000 rows so far.\n",
      "[2020-11-05 09:40:24,518] {hive_server_hook:162} INFO - Written 1210000 rows so far.\n",
      "[2020-11-05 09:40:25,351] {hive_server_hook:162} INFO - Written 1220000 rows so far.\n",
      "[2020-11-05 09:40:26,154] {hive_server_hook:162} INFO - Written 1230000 rows so far.\n",
      "[2020-11-05 09:40:26,882] {hive_server_hook:162} INFO - Written 1240000 rows so far.\n",
      "[2020-11-05 09:40:27,667] {hive_server_hook:162} INFO - Written 1250000 rows so far.\n",
      "[2020-11-05 09:40:28,454] {hive_server_hook:162} INFO - Written 1260000 rows so far.\n",
      "[2020-11-05 09:40:29,252] {hive_server_hook:162} INFO - Written 1270000 rows so far.\n",
      "[2020-11-05 09:40:29,996] {hive_server_hook:162} INFO - Written 1280000 rows so far.\n",
      "[2020-11-05 09:40:30,812] {hive_server_hook:162} INFO - Written 1290000 rows so far.\n",
      "[2020-11-05 09:40:31,601] {hive_server_hook:162} INFO - Written 1300000 rows so far.\n",
      "[2020-11-05 09:40:32,403] {hive_server_hook:162} INFO - Written 1310000 rows so far.\n",
      "[2020-11-05 09:40:33,215] {hive_server_hook:162} INFO - Written 1320000 rows so far.\n",
      "[2020-11-05 09:40:33,953] {hive_server_hook:162} INFO - Written 1330000 rows so far.\n",
      "[2020-11-05 09:40:34,753] {hive_server_hook:162} INFO - Written 1340000 rows so far.\n",
      "[2020-11-05 09:40:35,547] {hive_server_hook:162} INFO - Written 1350000 rows so far.\n",
      "[2020-11-05 09:40:36,337] {hive_server_hook:162} INFO - Written 1360000 rows so far.\n",
      "[2020-11-05 09:40:37,071] {hive_server_hook:162} INFO - Written 1370000 rows so far.\n",
      "[2020-11-05 09:40:37,863] {hive_server_hook:162} INFO - Written 1380000 rows so far.\n",
      "[2020-11-05 09:40:38,637] {hive_server_hook:162} INFO - Written 1390000 rows so far.\n",
      "[2020-11-05 09:40:39,433] {hive_server_hook:162} INFO - Written 1400000 rows so far.\n",
      "[2020-11-05 09:40:40,160] {hive_server_hook:162} INFO - Written 1410000 rows so far.\n",
      "[2020-11-05 09:40:40,947] {hive_server_hook:162} INFO - Written 1420000 rows so far.\n",
      "[2020-11-05 09:40:41,726] {hive_server_hook:162} INFO - Written 1430000 rows so far.\n",
      "[2020-11-05 09:40:42,527] {hive_server_hook:162} INFO - Written 1440000 rows so far.\n",
      "[2020-11-05 09:40:43,277] {hive_server_hook:162} INFO - Written 1450000 rows so far.\n",
      "[2020-11-05 09:40:43,291] {hive_server_hook:162} INFO - Written 1450163 rows so far.\n",
      "[2020-11-05 09:40:43,301] {hiveserver2:265} INFO - Closing active operation\n",
      "[2020-11-05 09:40:43,316] {hive_server_hook:163} INFO - Done. Loaded a total of 1450163 rows.\n"
     ]
    }
   ],
   "source": [
    "#读取采购清洗完的数据\n",
    "sql = \"\"\"\n",
    "SELECT purchase_order_id as car_id,\n",
    "       brand_code,\n",
    "       brand_name,\n",
    "       series_code,\n",
    "       series_name,\n",
    "       model_code,\n",
    "       model_name,\n",
    "       cast(mileage/10000 AS DECIMAL(10,2)) AS mileage_std,\n",
    "       color AS color_name,\n",
    "       first_license_date as first_license_plate_date,\n",
    "       province_name,\n",
    "       city_name,\n",
    "       cast(purchase_price/10000 AS DECIMAL(10,2)) AS purchase_price,\n",
    "       date(pay_time) as order_create_time,\n",
    "       age AS license_month,\n",
    "       residual,\n",
    "       -- 需要按照当年情况来修改\n",
    "       datediff(\"2020-12-31 00:00:00\", pay_time) AS days,\n",
    "       cast(year(first_license_date) AS INT) AS license_year\n",
    "FROM db_data.mid_car_dfc_purchase_order_flag_b\n",
    "WHERE flag = 0 \n",
    "and pay_time is not null\n",
    " -- 确认选取建模时间\n",
    "and pay_time<=\"2020-11-02\"\n",
    "and province_name is not null\n",
    "and city_name is not null\n",
    "\"\"\"\n",
    "dtype={'uid':str}\n",
    "data= read_from_hive2('mid_car_dfc_purchase_order_flag',sql,dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T01:51:59.930588Z",
     "start_time": "2020-03-24T01:51:59.068245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1450163 entries, 0 to 1450162\n",
      "Data columns (total 18 columns):\n",
      "car_id                      1450163 non-null int64\n",
      "brand_code                  1450059 non-null object\n",
      "brand_name                  1450059 non-null object\n",
      "series_code                 1450059 non-null object\n",
      "series_name                 1450059 non-null object\n",
      "model_code                  1450163 non-null object\n",
      "model_name                  1450059 non-null object\n",
      "mileage_std                 1450163 non-null float64\n",
      "color_name                  1449920 non-null object\n",
      "first_license_plate_date    1450163 non-null object\n",
      "province_name               1450163 non-null object\n",
      "city_name                   1450163 non-null object\n",
      "purchase_price              1450163 non-null float64\n",
      "order_create_time           1450163 non-null object\n",
      "license_month               1450163 non-null int64\n",
      "residual                    1450163 non-null float64\n",
      "days                        1450163 non-null int64\n",
      "license_year                1450163 non-null int64\n",
      "dtypes: float64(3), int64(4), object(11)\n",
      "memory usage: 199.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info(null_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T01:52:06.844769Z",
     "start_time": "2020-03-24T01:52:05.537584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_id</th>\n",
       "      <th>brand_code</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>series_code</th>\n",
       "      <th>series_name</th>\n",
       "      <th>model_code</th>\n",
       "      <th>model_name</th>\n",
       "      <th>mileage_std</th>\n",
       "      <th>color_name</th>\n",
       "      <th>first_license_plate_date</th>\n",
       "      <th>province_name</th>\n",
       "      <th>city_name</th>\n",
       "      <th>purchase_price</th>\n",
       "      <th>order_create_time</th>\n",
       "      <th>license_month</th>\n",
       "      <th>residual</th>\n",
       "      <th>days</th>\n",
       "      <th>license_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>929372</td>\n",
       "      <td>brand-49</td>\n",
       "      <td>丰田</td>\n",
       "      <td>series-1072</td>\n",
       "      <td>汉兰达</td>\n",
       "      <td>054186468</td>\n",
       "      <td>2013款  汉兰达  2.7L 两驱7座探索版</td>\n",
       "      <td>7.20</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>湖北</td>\n",
       "      <td>武汉</td>\n",
       "      <td>18.8</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>51</td>\n",
       "      <td>0.571776</td>\n",
       "      <td>1007</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1027344</td>\n",
       "      <td>brand-49</td>\n",
       "      <td>丰田</td>\n",
       "      <td>series-1072</td>\n",
       "      <td>汉兰达</td>\n",
       "      <td>054186468</td>\n",
       "      <td>2013款  汉兰达  2.7L 两驱7座探索版</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>黑龙江</td>\n",
       "      <td>哈尔滨</td>\n",
       "      <td>19.8</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>51</td>\n",
       "      <td>0.602190</td>\n",
       "      <td>950</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2335083</td>\n",
       "      <td>brand-49</td>\n",
       "      <td>丰田</td>\n",
       "      <td>series-1072</td>\n",
       "      <td>汉兰达</td>\n",
       "      <td>054186468</td>\n",
       "      <td>2013款  汉兰达  2.7L 两驱7座探索版</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-11-01</td>\n",
       "      <td>辽宁</td>\n",
       "      <td>大连</td>\n",
       "      <td>12.2</td>\n",
       "      <td>2020-10-10</td>\n",
       "      <td>84</td>\n",
       "      <td>0.371046</td>\n",
       "      <td>82</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63147</td>\n",
       "      <td>brand-49</td>\n",
       "      <td>丰田</td>\n",
       "      <td>series-1072</td>\n",
       "      <td>汉兰达</td>\n",
       "      <td>054186468</td>\n",
       "      <td>2013款  汉兰达  2.7L 两驱7座探索版</td>\n",
       "      <td>8.35</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-11-01</td>\n",
       "      <td>山东</td>\n",
       "      <td>济南</td>\n",
       "      <td>18.8</td>\n",
       "      <td>2016-07-30</td>\n",
       "      <td>33</td>\n",
       "      <td>0.571776</td>\n",
       "      <td>1615</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>662674</td>\n",
       "      <td>brand-49</td>\n",
       "      <td>丰田</td>\n",
       "      <td>series-1072</td>\n",
       "      <td>汉兰达</td>\n",
       "      <td>054186468</td>\n",
       "      <td>2013款  汉兰达  2.7L 两驱7座探索版</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>黑龙江</td>\n",
       "      <td>哈尔滨</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2017-09-23</td>\n",
       "      <td>37</td>\n",
       "      <td>0.669100</td>\n",
       "      <td>1195</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    car_id brand_code brand_name  series_code series_name model_code  \\\n",
       "0   929372   brand-49         丰田  series-1072         汉兰达  054186468   \n",
       "1  1027344   brand-49         丰田  series-1072         汉兰达  054186468   \n",
       "2  2335083   brand-49         丰田  series-1072         汉兰达  054186468   \n",
       "3    63147   brand-49         丰田  series-1072         汉兰达  054186468   \n",
       "4   662674   brand-49         丰田  series-1072         汉兰达  054186468   \n",
       "\n",
       "                 model_name  mileage_std color_name first_license_plate_date  \\\n",
       "0  2013款  汉兰达  2.7L 两驱7座探索版         7.20          4               2014-01-01   \n",
       "1  2013款  汉兰达  2.7L 两驱7座探索版         6.00          4               2014-03-01   \n",
       "2  2013款  汉兰达  2.7L 两驱7座探索版         8.00          4               2013-11-01   \n",
       "3  2013款  汉兰达  2.7L 两驱7座探索版         8.35          4               2013-11-01   \n",
       "4  2013款  汉兰达  2.7L 两驱7座探索版         5.00          3               2014-09-01   \n",
       "\n",
       "  province_name city_name  purchase_price order_create_time  license_month  \\\n",
       "0            湖北        武汉            18.8        2018-03-30             51   \n",
       "1           黑龙江       哈尔滨            19.8        2018-05-26             51   \n",
       "2            辽宁        大连            12.2        2020-10-10             84   \n",
       "3            山东        济南            18.8        2016-07-30             33   \n",
       "4           黑龙江       哈尔滨            22.0        2017-09-23             37   \n",
       "\n",
       "   residual  days  license_year  \n",
       "0  0.571776  1007          2014  \n",
       "1  0.602190   950          2014  \n",
       "2  0.371046    82          2013  \n",
       "3  0.571776  1615          2013  \n",
       "4  0.669100  1195          2014  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['mileage_std'] = data['mileage_std'].astype('float')\n",
    "data['purchase_price'] = data['purchase_price'].astype('float')\n",
    "data['license_month'] = data['license_month'].astype('int')\n",
    "data['residual'] = data['residual'].astype('float')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T01:52:48.379099Z",
     "start_time": "2020-03-24T01:52:44.145640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并前数据数目为:1450163, 车型数量为：27744\n",
      "<---------------------------------------->\n",
      "合并后数据数目为:1446922, 车型数量为：27064\n"
     ]
    }
   ],
   "source": [
    "# 读取可估价的车型 224239\n",
    "model = pd.read_csv(curr_dir+\"2020-11-02版车型参数及独热编码.csv\", header=0, low_memory=False)\n",
    "model = model[['model_code', 'model_year', 'new_car_price','year_1', 'year_2', 'year_3', 'year_4', 'year_5', 'year_6',\n",
    "                     'year_7', 'year_8', 'year_9', 'year_10', 'year_11', 'year_12', 'year_13', \n",
    "                     'year_14', 'year_15', 'year_16','rate','rate_count']]\n",
    "print(\"合并前数据数目为:%d, 车型数量为：%d\" % (data.shape[0], len(data['model_code'].unique())))\n",
    "data['model_code'] = data['model_code'].astype('str')\n",
    "data = pd.merge(data, model, on='model_code', how='inner')\n",
    "print(\"<---------------------------------------->\")\n",
    "print(\"合并后数据数目为:%d, 车型数量为：%d\" % (data.shape[0], len(data['model_code'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T02:03:49.686118Z",
     "start_time": "2020-03-24T02:03:44.483936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "增加限制后，数据数量为:1399647, 车型数量为:25303\n"
     ]
    }
   ],
   "source": [
    "#去掉一些不合理的数据 meimei\n",
    "data_m = data[(data['mileage_std']>=0.01) & (data['mileage_std']<=50)]\n",
    "data_m = data_m[(data_m['purchase_price']>=0.2) & (data_m['purchase_price']<=300)]\n",
    "data_m = data_m[(data_m['license_month']>=1) & (data_m['license_month']<=180)]\n",
    "data_m = data_m[(data_m['residual']>=0.02) & (data_m['residual']<1.2)]\n",
    "data_m = data_m[(data_m['model_year']>=2006)]\n",
    "data_m = data_m[data_m['license_year']>=2005]\n",
    "data_m = data_m[(data_m['new_car_price']>=0.85) & (data_m['new_car_price']<=500)]\n",
    "\n",
    "#需要计算\n",
    "data_m['per_mile'] = round(data_m['mileage_std']/(data_m['license_month']/12),2)\n",
    "\n",
    "#需要计算\n",
    "data_m['year_err'] = data_m['license_year'] - data_m['model_year']\n",
    "data_m = data_m[(data_m['year_err']>=-2) & (data_m['year_err']<=6)]\n",
    "print(\"增加限制后，数据数量为:%d, 车型数量为:%d\" % (data_m.shape[0], len(data_m['model_code'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T02:04:43.686839Z",
     "start_time": "2020-03-24T02:04:38.422942Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1399647 entries, 0 to 1399646\n",
      "Data columns (total 71 columns):\n",
      "car_id                      1399647 non-null int64\n",
      "brand_code                  1399543 non-null object\n",
      "brand_name                  1399543 non-null object\n",
      "series_code                 1399543 non-null object\n",
      "series_name                 1399543 non-null object\n",
      "model_code                  1399647 non-null object\n",
      "model_name                  1399543 non-null object\n",
      "mileage_std                 1399647 non-null float64\n",
      "color_name                  1399405 non-null object\n",
      "first_license_plate_date    1399647 non-null object\n",
      "province_name               1399647 non-null object\n",
      "city_name                   1399647 non-null object\n",
      "purchase_price              1399647 non-null float64\n",
      "order_create_time           1399647 non-null object\n",
      "license_month               1399647 non-null int64\n",
      "residual                    1399647 non-null float64\n",
      "days                        1399647 non-null int64\n",
      "license_year                1399647 non-null int64\n",
      "model_year                  1399647 non-null int64\n",
      "new_car_price               1399647 non-null float64\n",
      "year_1                      1399647 non-null float64\n",
      "year_2                      1399647 non-null float64\n",
      "year_3                      1399647 non-null float64\n",
      "year_4                      1399647 non-null float64\n",
      "year_5                      1399647 non-null float64\n",
      "year_6                      1399647 non-null float64\n",
      "year_7                      1399647 non-null float64\n",
      "year_8                      1399647 non-null float64\n",
      "year_9                      1399647 non-null float64\n",
      "year_10                     1399647 non-null float64\n",
      "year_11                     1399647 non-null float64\n",
      "year_12                     1399647 non-null float64\n",
      "year_13                     1399647 non-null float64\n",
      "year_14                     1399647 non-null float64\n",
      "year_15                     1399647 non-null float64\n",
      "year_16                     1399647 non-null float64\n",
      "rate                        1399647 non-null float64\n",
      "rate_count                  1399647 non-null float64\n",
      "per_mile                    1399647 non-null float64\n",
      "year_err                    1399647 non-null int64\n",
      "province_name0              1399647 non-null int64\n",
      "province_name1              1399647 non-null int64\n",
      "province_name2              1399647 non-null int64\n",
      "province_name3              1399647 non-null int64\n",
      "province_name4              1399647 non-null int64\n",
      "province_name5              1399647 non-null int64\n",
      "province_name6              1399647 non-null int64\n",
      "province_name7              1399647 non-null int64\n",
      "province_name8              1399647 non-null int64\n",
      "province_name9              1399647 non-null int64\n",
      "province_name10             1399647 non-null int64\n",
      "province_name11             1399647 non-null int64\n",
      "province_name12             1399647 non-null int64\n",
      "province_name13             1399647 non-null int64\n",
      "province_name14             1399647 non-null int64\n",
      "province_name15             1399647 non-null int64\n",
      "province_name16             1399647 non-null int64\n",
      "province_name17             1399647 non-null int64\n",
      "province_name18             1399647 non-null int64\n",
      "province_name19             1399647 non-null int64\n",
      "province_name20             1399647 non-null int64\n",
      "province_name21             1399647 non-null int64\n",
      "province_name22             1399647 non-null int64\n",
      "province_name23             1399647 non-null int64\n",
      "province_name24             1399647 non-null int64\n",
      "province_name25             1399647 non-null int64\n",
      "province_name26             1399647 non-null int64\n",
      "province_name27             1399647 non-null int64\n",
      "province_name28             1399647 non-null int64\n",
      "province_name29             1399647 non-null int64\n",
      "province_name30             1399647 non-null int64\n",
      "dtypes: float64(23), int64(37), object(11)\n",
      "memory usage: 768.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# 读取编码完成的省份数据\n",
    "province = pd.read_csv(\"province_new.csv\", header=0, low_memory=False)\n",
    "data2m = pd.merge(data_m, province, how='left', on='province_name')\n",
    "data2m.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T02:59:17.754773Z",
     "start_time": "2020-03-24T02:07:04.387806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====\n"
     ]
    }
   ],
   "source": [
    "# 该函数为计算保值率 \n",
    "def computer_with_license_month(tar):\n",
    "    license_month = tar['license_month']\n",
    "    if(license_month <= 12):\n",
    "        return tar['year_1']\n",
    "    else:\n",
    "        year = license_month//12\n",
    "        #当前年保值率\n",
    "        keep_max = tar[\"year_\"+str(int(year))]\n",
    "        #下一年的保值率\n",
    "        keep_min = tar[\"year_\"+str(int(year+1))]\n",
    "        \n",
    "        #相比于上一年，已经过了几个月\n",
    "        mon = license_month - 12 * year\n",
    "        tem = (keep_max-keep_min)/12\n",
    "        \n",
    "        return round(keep_max - tem*mon, 4)\n",
    "    #return tar\n",
    "data2m['keep_value'] = data2m[['license_month','year_1', 'year_2', 'year_3', 'year_4','year_5', 'year_6', 'year_7', 'year_8', 'year_9', 'year_10', 'year_11','year_12', 'year_13', 'year_14', 'year_15', 'year_16']].to_dict(orient='records')\n",
    "print(\"====\")\n",
    "data2m['keep_value'] = data2m['keep_value'].map(lambda tar:computer_with_license_month(tar))\n",
    "#data2m = data2m.apply(computer_with_license_month, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "quality = pd.read_csv(curr_dir+\"2020-11-02版车型参数及独热编码.csv\", header=0, low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T04:26:14.321985Z",
     "start_time": "2020-03-24T03:50:49.730360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65250, 3)\n"
     ]
    }
   ],
   "source": [
    "data3m = data2m.drop(['year_1', 'year_2', 'year_3', 'year_4', \n",
    "                    'year_5', 'year_6', 'year_7', 'year_8', \n",
    "                    'year_9', 'year_10', 'year_11', 'year_12', \n",
    "                    'year_13', 'year_14', 'year_15', 'year_16'], axis=1)\n",
    "\n",
    "quality = pd.read_csv(curr_dir+\"2020-11-02版车型参数及独热编码.csv\", header=0, low_memory=False)\n",
    "quality = quality[['model_code', 'quality_mile', 'quality_year']]\n",
    "print(quality.shape)\n",
    "\n",
    "data3m = pd.merge(data3m, quality, how='left', on='model_code')\n",
    "\n",
    "def get_quality(license_month,mileage_std,quality_mile,quality_year):\n",
    "    year = round(license_month/12, 2)\n",
    "    if mileage_std < quality_mile and year< quality_year:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "       \n",
    "data3m['quality'] = list(map(lambda license_month,mileage_std,quality_mile,quality_year:get_quality(license_month,mileage_std,quality_mile,quality_year),\n",
    "          data3m['license_month'],data3m['mileage_std'],data3m['quality_mile'],data3m['quality_year']))\n",
    "data3m = data3m.drop(['quality_mile', 'quality_year'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T07:44:11.107825Z",
     "start_time": "2020-03-24T05:46:29.265160Z"
    }
   },
   "outputs": [],
   "source": [
    "#计算一下log\n",
    "# def feature_log(tar):\n",
    "#     tar['mile_log'] = round(math.log(tar['mileage_std'], 2), 4)\n",
    "#     tar['license_month_log'] = round(math.log(tar['license_month'], 2), 4)\n",
    "#     tar['new_car_price_log'] = round(math.log(tar['new_car_price'], 2), 4)\n",
    "#     return tar\n",
    "#data3m = data3m.apply(feature_log, axis=1)\n",
    "# 切换使用 np.log2 效率高一些 \n",
    "data3m['mile_log']=round(np.log2(data3m['mileage_std']), 4)\n",
    "data3m['license_month_log']=round(np.log2(data3m['license_month']), 4)\n",
    "# data3m['license_month_log']=data3m['license_month']\n",
    "data3m['new_car_price_log']=round(np.log2(data3m['new_car_price']), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T08:09:34.253806Z",
     "start_time": "2020-03-24T08:06:34.191193Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据筛选  查看每个车型对应的建模数据\n",
    "data_counts_mei = data3m.groupby('model_code')['car_id'].count().rename('count').reset_index()\n",
    "data5m = pd.merge(data3m, data_counts_mei, how='left', on='model_code')\n",
    "data5m = data5m.reset_index(drop=True)\n",
    "data5m.to_csv(curr_dir+\"2020-11-02版带count处理完成的采购数据m.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 按照model_code划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T08:14:48.580906Z",
     "start_time": "2020-03-24T08:14:47.669082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "交易条数超过5条的数据量是:1381029, 车型数量是:16706\n",
      "交易条数少于5条的数据量是:18618, 车型数量是:8597\n"
     ]
    }
   ],
   "source": [
    "# 之前测试了两种 数据，所以有两条记录。 \n",
    "\n",
    "#交易条数超过5条\n",
    "datahm = data5m[data5m['count']>=5]\n",
    "#交易条数少于5条\n",
    "datalm = data5m[data5m['count']<5]\n",
    "\n",
    "print(\"交易条数超过5条的数据量是:%d, 车型数量是:%d\" % (datahm.shape[0], len(datahm['model_code'].unique())))\n",
    "print(\"交易条数少于5条的数据量是:%d, 车型数量是:%d\" % (datalm.shape[0], len(datalm['model_code'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T08:15:25.272374Z",
     "start_time": "2020-03-24T08:15:15.721347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1104823, 61)\n",
      "(276206, 61)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "单个model_code, 交易记录数超过5条, 使用\n",
    "StratifiedShuffleSplit来进行划分, 测试训练\n",
    "比例2:8; 单个model_code交易记录数少于5条, \n",
    "手动划分\n",
    "\"\"\"\n",
    "#step1:首先划分数据量超过5条的\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "\n",
    "stratified = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "\n",
    "# 切meimei 的数据\n",
    "for sub_set1, sub_set2 in stratified.split(datahm, datahm['model_code']):\n",
    "    train_1m = datahm.iloc[sub_set1]\n",
    "    test_1m = datahm.iloc[sub_set2]\n",
    "print(train_1m.shape)\n",
    "print(test_1m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/souche/projects/calculation/py3dev_new/lib/python3.5/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "datalm['car_id'] = datalm['car_id'].map(lambda x:str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T08:41:36.360529Z",
     "start_time": "2020-03-24T08:33:47.708403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已完成0个model_code数据集划分, 共8597个, 进度0.00%\n",
      "已完成1000个model_code数据集划分, 共8597个, 进度11.63%\n",
      "已完成2000个model_code数据集划分, 共8597个, 进度23.26%\n",
      "已完成3000个model_code数据集划分, 共8597个, 进度34.90%\n",
      "已完成4000个model_code数据集划分, 共8597个, 进度46.53%\n",
      "已完成5000个model_code数据集划分, 共8597个, 进度58.16%\n",
      "已完成6000个model_code数据集划分, 共8597个, 进度69.79%\n",
      "已完成7000个model_code数据集划分, 共8597个, 进度81.42%\n",
      "已完成8000个model_code数据集划分, 共8597个, 进度93.06%\n"
     ]
    }
   ],
   "source": [
    "#按对应比例划分训练集和测试集\n",
    "from sklearn.utils import shuffle\n",
    "def split_data(data):\n",
    "    model_code_list = list(data['model_code'].unique())\n",
    "    #用来保存抽取的训练数据\n",
    "    data_train = data[data['car_id']==\"192044\"]\n",
    "    #用来保存抽取的测试数据\n",
    "    data_test = data[data['car_id']==\"1112363\"]\n",
    "    for i in range(len(model_code_list)):\n",
    "        model_code = model_code_list[i]\n",
    "        if model_code==\"12365-n\":\n",
    "            continue\n",
    "        data_tem = data[data['model_code']==model_code]\n",
    "        if(data_tem.shape[0]==1):\n",
    "            data_train = pd.concat([data_train, data_tem])\n",
    "        elif(data_tem.shape[0]==2):\n",
    "            data_tem_test = data_tem.iloc[0:1, :]\n",
    "            data_tem_train = data_tem.iloc[1:2, :]\n",
    "            data_test = pd.concat([data_test, data_tem_test])\n",
    "            data_train = pd.concat([data_train, data_tem_train])\n",
    "        #三条以上的数据才能划分训练集和测试集\n",
    "        else:\n",
    "            data_tem = shuffle(data_tem)\n",
    "            n = int(round(data_tem.shape[0]*0.2))\n",
    "            data_tem_test = data_tem.iloc[0:n, :]\n",
    "            data_tem_train = data_tem.iloc[n:, :]\n",
    "            \n",
    "            data_test = pd.concat([data_test, data_tem_test])\n",
    "            data_train = pd.concat([data_train, data_tem_train])\n",
    "        if(i%1000==0):\n",
    "            print(\"已完成%d个model_code数据集划分, 共%d个, 进度%.2f%%\" % \n",
    "                  (i, len(model_code_list), i/len(model_code_list)*100))\n",
    "    return data_train, data_test\n",
    "\n",
    "train_2m, test_2m = split_data(datalm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T08:43:51.912970Z",
     "start_time": "2020-03-24T08:43:51.907623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12943, 61)\n",
      "(5675, 61)\n"
     ]
    }
   ],
   "source": [
    "print(train_2m.shape)\n",
    "print(test_2m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T08:44:21.276741Z",
     "start_time": "2020-03-24T08:44:09.215464Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data_trainm = pd.concat([train_1m, train_2m])\n",
    "data_trainm = data_trainm.reset_index(drop=True)\n",
    "\n",
    "data_testm = pd.concat([test_1m, test_2m])\n",
    "data_testm = data_testm.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T08:54:30.549739Z",
     "start_time": "2020-03-24T08:53:01.273858Z"
    }
   },
   "outputs": [],
   "source": [
    "data_trainm.to_csv(curr_dir+\"2020-11-02版采购数据data_train2.csv\", header=True, index=False)\n",
    "data_testm.to_csv(curr_dir+\"2020-11-02版采购数据data_test2.csv\", header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
