{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:00:30.061925Z",
     "start_time": "2020-03-23T09:00:28.611510Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAYU_HOME : /home/souche/projects/datacenter-etl-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/souche/projects/calculation/py3dev_new/lib/python3.5/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-11 15:48:40,395] {driver:120} INFO - Generating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "[2020-11-11 15:48:40,424] {driver:120} INFO - Generating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "[2020-11-11 15:48:42,961] {<ipython-input-1-72bb441ecf4d>:61} INFO - 当前日期: 2020-11-11\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import logging\n",
    "import datetime\n",
    "from logging.handlers import TimedRotatingFileHandler\n",
    "from logging.handlers import RotatingFileHandler\n",
    "from sklearn.externals import joblib\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "from dayu.hooks.oss_hook import OSSHook\n",
    "\n",
    "from dayu.hooks.hive_server_hook import HiveServerHook\n",
    "from dayu.hooks.hive_cli_hook import HiveCliHook\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from fastFM import sgd\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csc_matrix\n",
    "import time\n",
    "from sklearn.metrics import auc,accuracy_score,roc_curve,roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix,recall_score\n",
    "from sklearn import  metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def split_table_name(datain):\n",
    "    new_cols = []\n",
    "    for column in datain.columns:\n",
    "        if(len(column.split('.'))<2):\n",
    "            return datain\n",
    "        tb_name, col_name = column.split('.')\n",
    "        new_cols.append((column, col_name))\n",
    "    datain = datain.rename(columns=dict(new_cols))\n",
    "    return datain\n",
    "\n",
    "def read_from_hive2(output_file_name,insql,dtype):\n",
    "    filename = output_file_name\n",
    "    filepath = curr_dir+filename\n",
    "    hive = HiveServerHook(\"warehouse_hive\")\n",
    "    hive.to_csv(insql,filepath , delimiter=',',lineterminator='\\n', output_header=True)\n",
    "    outdata = pd.read_csv(filepath, header=0,dtype=dtype)\n",
    "    # 去除列名中带有的表名\n",
    "    outdata = split_table_name(outdata)\n",
    "    return outdata\n",
    "def date_time_sub(startTime,endTime,date_format):\n",
    "    try:\n",
    "        startTime= datetime.datetime.strptime(startTime,date_format)\n",
    "        endTime= datetime.datetime.strptime(endTime,date_format)\n",
    "        return (endTime - startTime).days\n",
    "    except:\n",
    "        pass\n",
    "curr_date = str(datetime.datetime.now())[0:10]\n",
    "logging.info('当前日期: %s'%(curr_date))\n",
    "curr_dir = '/home/souche/qiongjiu/hgc/'\n",
    "curr_date=str(datetime.datetime.now())[0:10]\n",
    "hive_cli = HiveCliHook(\"warehouse_hive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:30:56.916024Z",
     "start_time": "2020-03-23T09:27:37.917394Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-11 15:48:43,069] {hiveserver2:138} INFO - Using database default as default\n",
      "[2020-11-11 15:48:43,262] {hive_server_hook:112} INFO - Running query: \n",
      "SELECT order_sn as car_id,\n",
      "       brand_code,\n",
      "       brand_name,\n",
      "       series_code,\n",
      "       series_name,\n",
      "       model_code,\n",
      "       model_name,\n",
      "       cast(mileage/10000 AS DECIMAL(10,2)) AS mileage_std,\n",
      "       color AS color_name,\n",
      "       first_license_date as first_license_plate_date,\n",
      "       province_name,\n",
      "       city_name,\n",
      "       cast(real_pay_amount/10000 AS DECIMAL(10,2)) AS price,\n",
      "       date(pay_time) as pay_time,\n",
      "       age AS license_month,\n",
      "       residual,\n",
      "       datediff(\"2020-12-31 00:00:00\", pay_time) AS days,\n",
      "       cast(year(first_license_date) AS INT) AS license_year\n",
      "FROM db_data.mid_car_dfc_sale_order_flag_b\n",
      "WHERE flag = 0\n",
      "and trade_type !='B2B' \n",
      "and pay_time is not null\n",
      "and pay_time<=\"2020-11-02\"\n",
      "and province_name is not null\n",
      "and city_name is not null\n",
      "\n",
      "[2020-11-11 15:48:44,381] {hive_server_hook:162} INFO - Written 10000 rows so far.\n",
      "[2020-11-11 15:48:45,172] {hive_server_hook:162} INFO - Written 20000 rows so far.\n",
      "[2020-11-11 15:48:45,976] {hive_server_hook:162} INFO - Written 30000 rows so far.\n",
      "[2020-11-11 15:48:46,777] {hive_server_hook:162} INFO - Written 40000 rows so far.\n",
      "[2020-11-11 15:48:47,502] {hive_server_hook:162} INFO - Written 50000 rows so far.\n",
      "[2020-11-11 15:48:48,303] {hive_server_hook:162} INFO - Written 60000 rows so far.\n",
      "[2020-11-11 15:48:49,229] {hive_server_hook:162} INFO - Written 70000 rows so far.\n",
      "[2020-11-11 15:48:50,164] {hive_server_hook:162} INFO - Written 80000 rows so far.\n",
      "[2020-11-11 15:48:51,031] {hive_server_hook:162} INFO - Written 90000 rows so far.\n",
      "[2020-11-11 15:48:51,948] {hive_server_hook:162} INFO - Written 100000 rows so far.\n",
      "[2020-11-11 15:48:52,898] {hive_server_hook:162} INFO - Written 110000 rows so far.\n",
      "[2020-11-11 15:48:53,826] {hive_server_hook:162} INFO - Written 120000 rows so far.\n",
      "[2020-11-11 15:48:54,738] {hive_server_hook:162} INFO - Written 130000 rows so far.\n",
      "[2020-11-11 15:48:55,677] {hive_server_hook:162} INFO - Written 140000 rows so far.\n",
      "[2020-11-11 15:48:56,625] {hive_server_hook:162} INFO - Written 150000 rows so far.\n",
      "[2020-11-11 15:48:57,553] {hive_server_hook:162} INFO - Written 160000 rows so far.\n",
      "[2020-11-11 15:48:58,500] {hive_server_hook:162} INFO - Written 170000 rows so far.\n",
      "[2020-11-11 15:48:59,365] {hive_server_hook:162} INFO - Written 180000 rows so far.\n",
      "[2020-11-11 15:49:00,305] {hive_server_hook:162} INFO - Written 190000 rows so far.\n",
      "[2020-11-11 15:49:01,248] {hive_server_hook:162} INFO - Written 200000 rows so far.\n",
      "[2020-11-11 15:49:02,168] {hive_server_hook:162} INFO - Written 210000 rows so far.\n",
      "[2020-11-11 15:49:03,036] {hive_server_hook:162} INFO - Written 220000 rows so far.\n",
      "[2020-11-11 15:49:03,949] {hive_server_hook:162} INFO - Written 230000 rows so far.\n",
      "[2020-11-11 15:49:04,888] {hive_server_hook:162} INFO - Written 240000 rows so far.\n",
      "[2020-11-11 15:49:05,840] {hive_server_hook:162} INFO - Written 250000 rows so far.\n",
      "[2020-11-11 15:49:06,699] {hive_server_hook:162} INFO - Written 260000 rows so far.\n",
      "[2020-11-11 15:49:07,616] {hive_server_hook:162} INFO - Written 270000 rows so far.\n",
      "[2020-11-11 15:49:08,540] {hive_server_hook:162} INFO - Written 280000 rows so far.\n",
      "[2020-11-11 15:49:09,466] {hive_server_hook:162} INFO - Written 290000 rows so far.\n",
      "[2020-11-11 15:49:10,349] {hive_server_hook:162} INFO - Written 300000 rows so far.\n",
      "[2020-11-11 15:49:11,268] {hive_server_hook:162} INFO - Written 310000 rows so far.\n",
      "[2020-11-11 15:49:12,199] {hive_server_hook:162} INFO - Written 320000 rows so far.\n",
      "[2020-11-11 15:49:13,133] {hive_server_hook:162} INFO - Written 330000 rows so far.\n",
      "[2020-11-11 15:49:13,960] {hive_server_hook:162} INFO - Written 340000 rows so far.\n",
      "[2020-11-11 15:49:14,695] {hive_server_hook:162} INFO - Written 350000 rows so far.\n",
      "[2020-11-11 15:49:15,535] {hive_server_hook:162} INFO - Written 360000 rows so far.\n",
      "[2020-11-11 15:49:16,366] {hive_server_hook:162} INFO - Written 370000 rows so far.\n",
      "[2020-11-11 15:49:17,304] {hive_server_hook:162} INFO - Written 380000 rows so far.\n",
      "[2020-11-11 15:49:18,094] {hive_server_hook:162} INFO - Written 390000 rows so far.\n",
      "[2020-11-11 15:49:18,884] {hive_server_hook:162} INFO - Written 400000 rows so far.\n",
      "[2020-11-11 15:49:19,685] {hive_server_hook:162} INFO - Written 410000 rows so far.\n",
      "[2020-11-11 15:49:20,478] {hive_server_hook:162} INFO - Written 420000 rows so far.\n",
      "[2020-11-11 15:49:21,216] {hive_server_hook:162} INFO - Written 430000 rows so far.\n",
      "[2020-11-11 15:49:22,006] {hive_server_hook:162} INFO - Written 440000 rows so far.\n",
      "[2020-11-11 15:49:22,822] {hive_server_hook:162} INFO - Written 450000 rows so far.\n",
      "[2020-11-11 15:49:23,608] {hive_server_hook:162} INFO - Written 460000 rows so far.\n",
      "[2020-11-11 15:49:24,438] {hive_server_hook:162} INFO - Written 470000 rows so far.\n",
      "[2020-11-11 15:49:25,244] {hive_server_hook:162} INFO - Written 480000 rows so far.\n",
      "[2020-11-11 15:49:26,041] {hive_server_hook:162} INFO - Written 490000 rows so far.\n",
      "[2020-11-11 15:49:26,886] {hive_server_hook:162} INFO - Written 500000 rows so far.\n",
      "[2020-11-11 15:49:27,695] {hive_server_hook:162} INFO - Written 510000 rows so far.\n",
      "[2020-11-11 15:49:28,430] {hive_server_hook:162} INFO - Written 520000 rows so far.\n",
      "[2020-11-11 15:49:29,224] {hive_server_hook:162} INFO - Written 530000 rows so far.\n",
      "[2020-11-11 15:49:30,042] {hive_server_hook:162} INFO - Written 540000 rows so far.\n",
      "[2020-11-11 15:49:30,884] {hive_server_hook:162} INFO - Written 550000 rows so far.\n",
      "[2020-11-11 15:49:31,627] {hive_server_hook:162} INFO - Written 560000 rows so far.\n",
      "[2020-11-11 15:49:32,469] {hive_server_hook:162} INFO - Written 570000 rows so far.\n",
      "[2020-11-11 15:49:33,261] {hive_server_hook:162} INFO - Written 580000 rows so far.\n",
      "[2020-11-11 15:49:34,057] {hive_server_hook:162} INFO - Written 590000 rows so far.\n",
      "[2020-11-11 15:49:34,794] {hive_server_hook:162} INFO - Written 600000 rows so far.\n",
      "[2020-11-11 15:49:35,606] {hive_server_hook:162} INFO - Written 610000 rows so far.\n",
      "[2020-11-11 15:49:36,392] {hive_server_hook:162} INFO - Written 620000 rows so far.\n",
      "[2020-11-11 15:49:37,179] {hive_server_hook:162} INFO - Written 630000 rows so far.\n",
      "[2020-11-11 15:49:37,929] {hive_server_hook:162} INFO - Written 640000 rows so far.\n",
      "[2020-11-11 15:49:38,714] {hive_server_hook:162} INFO - Written 650000 rows so far.\n",
      "[2020-11-11 15:49:39,499] {hive_server_hook:162} INFO - Written 660000 rows so far.\n",
      "[2020-11-11 15:49:40,299] {hive_server_hook:162} INFO - Written 670000 rows so far.\n",
      "[2020-11-11 15:49:41,118] {hive_server_hook:162} INFO - Written 680000 rows so far.\n",
      "[2020-11-11 15:49:41,857] {hive_server_hook:162} INFO - Written 690000 rows so far.\n",
      "[2020-11-11 15:49:42,649] {hive_server_hook:162} INFO - Written 700000 rows so far.\n",
      "[2020-11-11 15:49:43,437] {hive_server_hook:162} INFO - Written 710000 rows so far.\n",
      "[2020-11-11 15:49:44,238] {hive_server_hook:162} INFO - Written 720000 rows so far.\n",
      "[2020-11-11 15:49:44,973] {hive_server_hook:162} INFO - Written 730000 rows so far.\n",
      "[2020-11-11 15:49:45,866] {hive_server_hook:162} INFO - Written 740000 rows so far.\n",
      "[2020-11-11 15:49:46,669] {hive_server_hook:162} INFO - Written 750000 rows so far.\n",
      "[2020-11-11 15:49:47,473] {hive_server_hook:162} INFO - Written 760000 rows so far.\n",
      "[2020-11-11 15:49:48,229] {hive_server_hook:162} INFO - Written 770000 rows so far.\n",
      "[2020-11-11 15:49:49,013] {hive_server_hook:162} INFO - Written 780000 rows so far.\n",
      "[2020-11-11 15:49:49,799] {hive_server_hook:162} INFO - Written 790000 rows so far.\n",
      "[2020-11-11 15:49:50,585] {hive_server_hook:162} INFO - Written 800000 rows so far.\n",
      "[2020-11-11 15:49:51,372] {hive_server_hook:162} INFO - Written 810000 rows so far.\n",
      "[2020-11-11 15:49:52,126] {hive_server_hook:162} INFO - Written 820000 rows so far.\n",
      "[2020-11-11 15:49:52,916] {hive_server_hook:162} INFO - Written 830000 rows so far.\n",
      "[2020-11-11 15:49:53,714] {hive_server_hook:162} INFO - Written 840000 rows so far.\n",
      "[2020-11-11 15:49:54,515] {hive_server_hook:162} INFO - Written 850000 rows so far.\n",
      "[2020-11-11 15:49:55,256] {hive_server_hook:162} INFO - Written 860000 rows so far.\n",
      "[2020-11-11 15:49:56,061] {hive_server_hook:162} INFO - Written 870000 rows so far.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-11 15:49:56,944] {hive_server_hook:162} INFO - Written 880000 rows so far.\n",
      "[2020-11-11 15:49:57,735] {hive_server_hook:162} INFO - Written 890000 rows so far.\n",
      "[2020-11-11 15:49:58,466] {hive_server_hook:162} INFO - Written 900000 rows so far.\n",
      "[2020-11-11 15:49:59,268] {hive_server_hook:162} INFO - Written 910000 rows so far.\n",
      "[2020-11-11 15:50:00,050] {hive_server_hook:162} INFO - Written 920000 rows so far.\n",
      "[2020-11-11 15:50:00,870] {hive_server_hook:162} INFO - Written 930000 rows so far.\n",
      "[2020-11-11 15:50:01,637] {hive_server_hook:162} INFO - Written 940000 rows so far.\n",
      "[2020-11-11 15:50:02,429] {hive_server_hook:162} INFO - Written 950000 rows so far.\n",
      "[2020-11-11 15:50:03,240] {hive_server_hook:162} INFO - Written 960000 rows so far.\n",
      "[2020-11-11 15:50:04,037] {hive_server_hook:162} INFO - Written 970000 rows so far.\n",
      "[2020-11-11 15:50:04,859] {hive_server_hook:162} INFO - Written 980000 rows so far.\n",
      "[2020-11-11 15:50:05,587] {hive_server_hook:162} INFO - Written 990000 rows so far.\n",
      "[2020-11-11 15:50:06,380] {hive_server_hook:162} INFO - Written 1000000 rows so far.\n",
      "[2020-11-11 15:50:07,197] {hive_server_hook:162} INFO - Written 1010000 rows so far.\n",
      "[2020-11-11 15:50:08,031] {hive_server_hook:162} INFO - Written 1020000 rows so far.\n",
      "[2020-11-11 15:50:08,762] {hive_server_hook:162} INFO - Written 1030000 rows so far.\n",
      "[2020-11-11 15:50:09,545] {hive_server_hook:162} INFO - Written 1040000 rows so far.\n",
      "[2020-11-11 15:50:10,345] {hive_server_hook:162} INFO - Written 1050000 rows so far.\n",
      "[2020-11-11 15:50:11,210] {hive_server_hook:162} INFO - Written 1060000 rows so far.\n",
      "[2020-11-11 15:50:11,950] {hive_server_hook:162} INFO - Written 1070000 rows so far.\n",
      "[2020-11-11 15:50:12,742] {hive_server_hook:162} INFO - Written 1080000 rows so far.\n",
      "[2020-11-11 15:50:13,523] {hive_server_hook:162} INFO - Written 1090000 rows so far.\n",
      "[2020-11-11 15:50:14,329] {hive_server_hook:162} INFO - Written 1100000 rows so far.\n",
      "[2020-11-11 15:50:15,066] {hive_server_hook:162} INFO - Written 1110000 rows so far.\n",
      "[2020-11-11 15:50:15,863] {hive_server_hook:162} INFO - Written 1120000 rows so far.\n",
      "[2020-11-11 15:50:16,706] {hive_server_hook:162} INFO - Written 1130000 rows so far.\n",
      "[2020-11-11 15:50:17,496] {hive_server_hook:162} INFO - Written 1140000 rows so far.\n",
      "[2020-11-11 15:50:18,286] {hive_server_hook:162} INFO - Written 1150000 rows so far.\n",
      "[2020-11-11 15:50:19,018] {hive_server_hook:162} INFO - Written 1160000 rows so far.\n",
      "[2020-11-11 15:50:19,834] {hive_server_hook:162} INFO - Written 1170000 rows so far.\n",
      "[2020-11-11 15:50:20,646] {hive_server_hook:162} INFO - Written 1180000 rows so far.\n",
      "[2020-11-11 15:50:21,443] {hive_server_hook:162} INFO - Written 1190000 rows so far.\n",
      "[2020-11-11 15:50:22,176] {hive_server_hook:162} INFO - Written 1200000 rows so far.\n",
      "[2020-11-11 15:50:22,964] {hive_server_hook:162} INFO - Written 1210000 rows so far.\n",
      "[2020-11-11 15:50:23,750] {hive_server_hook:162} INFO - Written 1220000 rows so far.\n",
      "[2020-11-11 15:50:24,543] {hive_server_hook:162} INFO - Written 1230000 rows so far.\n",
      "[2020-11-11 15:50:25,307] {hive_server_hook:162} INFO - Written 1240000 rows so far.\n",
      "[2020-11-11 15:50:26,109] {hive_server_hook:162} INFO - Written 1250000 rows so far.\n",
      "[2020-11-11 15:50:26,958] {hive_server_hook:162} INFO - Written 1260000 rows so far.\n",
      "[2020-11-11 15:50:27,809] {hive_server_hook:162} INFO - Written 1270000 rows so far.\n",
      "[2020-11-11 15:50:28,579] {hive_server_hook:162} INFO - Written 1280000 rows so far.\n",
      "[2020-11-11 15:50:29,377] {hive_server_hook:162} INFO - Written 1290000 rows so far.\n",
      "[2020-11-11 15:50:30,174] {hive_server_hook:162} INFO - Written 1300000 rows so far.\n",
      "[2020-11-11 15:50:31,039] {hive_server_hook:162} INFO - Written 1310000 rows so far.\n",
      "[2020-11-11 15:50:31,837] {hive_server_hook:162} INFO - Written 1320000 rows so far.\n",
      "[2020-11-11 15:50:32,591] {hive_server_hook:162} INFO - Written 1330000 rows so far.\n",
      "[2020-11-11 15:50:33,439] {hive_server_hook:162} INFO - Written 1340000 rows so far.\n",
      "[2020-11-11 15:50:34,250] {hive_server_hook:162} INFO - Written 1350000 rows so far.\n",
      "[2020-11-11 15:50:35,059] {hive_server_hook:162} INFO - Written 1360000 rows so far.\n",
      "[2020-11-11 15:50:35,886] {hive_server_hook:162} INFO - Written 1370000 rows so far.\n",
      "[2020-11-11 15:50:36,692] {hive_server_hook:162} INFO - Written 1380000 rows so far.\n",
      "[2020-11-11 15:50:37,501] {hive_server_hook:162} INFO - Written 1390000 rows so far.\n",
      "[2020-11-11 15:50:38,319] {hive_server_hook:162} INFO - Written 1400000 rows so far.\n",
      "[2020-11-11 15:50:39,111] {hive_server_hook:162} INFO - Written 1410000 rows so far.\n",
      "[2020-11-11 15:50:39,940] {hive_server_hook:162} INFO - Written 1420000 rows so far.\n",
      "[2020-11-11 15:50:40,759] {hive_server_hook:162} INFO - Written 1430000 rows so far.\n",
      "[2020-11-11 15:50:41,572] {hive_server_hook:162} INFO - Written 1440000 rows so far.\n",
      "[2020-11-11 15:50:42,392] {hive_server_hook:162} INFO - Written 1450000 rows so far.\n",
      "[2020-11-11 15:50:43,148] {hive_server_hook:162} INFO - Written 1460000 rows so far.\n",
      "[2020-11-11 15:50:43,955] {hive_server_hook:162} INFO - Written 1470000 rows so far.\n",
      "[2020-11-11 15:50:44,850] {hive_server_hook:162} INFO - Written 1480000 rows so far.\n",
      "[2020-11-11 15:50:45,642] {hive_server_hook:162} INFO - Written 1490000 rows so far.\n",
      "[2020-11-11 15:50:46,407] {hive_server_hook:162} INFO - Written 1500000 rows so far.\n",
      "[2020-11-11 15:50:47,228] {hive_server_hook:162} INFO - Written 1510000 rows so far.\n",
      "[2020-11-11 15:50:48,055] {hive_server_hook:162} INFO - Written 1520000 rows so far.\n",
      "[2020-11-11 15:50:48,868] {hive_server_hook:162} INFO - Written 1530000 rows so far.\n",
      "[2020-11-11 15:50:49,631] {hive_server_hook:162} INFO - Written 1540000 rows so far.\n",
      "[2020-11-11 15:50:50,453] {hive_server_hook:162} INFO - Written 1550000 rows so far.\n",
      "[2020-11-11 15:50:51,267] {hive_server_hook:162} INFO - Written 1560000 rows so far.\n",
      "[2020-11-11 15:50:52,208] {hive_server_hook:162} INFO - Written 1570000 rows so far.\n",
      "[2020-11-11 15:50:53,107] {hive_server_hook:162} INFO - Written 1580000 rows so far.\n",
      "[2020-11-11 15:50:53,931] {hive_server_hook:162} INFO - Written 1590000 rows so far.\n",
      "[2020-11-11 15:50:54,740] {hive_server_hook:162} INFO - Written 1600000 rows so far.\n",
      "[2020-11-11 15:50:55,590] {hive_server_hook:162} INFO - Written 1610000 rows so far.\n",
      "[2020-11-11 15:50:56,498] {hive_server_hook:162} INFO - Written 1620000 rows so far.\n",
      "[2020-11-11 15:50:57,256] {hive_server_hook:162} INFO - Written 1630000 rows so far.\n",
      "[2020-11-11 15:50:58,078] {hive_server_hook:162} INFO - Written 1640000 rows so far.\n",
      "[2020-11-11 15:50:58,889] {hive_server_hook:162} INFO - Written 1650000 rows so far.\n",
      "[2020-11-11 15:50:59,731] {hive_server_hook:162} INFO - Written 1660000 rows so far.\n",
      "[2020-11-11 15:51:00,492] {hive_server_hook:162} INFO - Written 1670000 rows so far.\n",
      "[2020-11-11 15:51:01,356] {hive_server_hook:162} INFO - Written 1680000 rows so far.\n",
      "[2020-11-11 15:51:02,155] {hive_server_hook:162} INFO - Written 1690000 rows so far.\n",
      "[2020-11-11 15:51:02,954] {hive_server_hook:162} INFO - Written 1700000 rows so far.\n",
      "[2020-11-11 15:51:03,703] {hive_server_hook:162} INFO - Written 1710000 rows so far.\n",
      "[2020-11-11 15:51:04,502] {hive_server_hook:162} INFO - Written 1720000 rows so far.\n",
      "[2020-11-11 15:51:05,334] {hive_server_hook:162} INFO - Written 1730000 rows so far.\n",
      "[2020-11-11 15:51:06,141] {hive_server_hook:162} INFO - Written 1740000 rows so far.\n",
      "[2020-11-11 15:51:06,894] {hive_server_hook:162} INFO - Written 1750000 rows so far.\n",
      "[2020-11-11 15:51:07,242] {hive_server_hook:162} INFO - Written 1754472 rows so far.\n",
      "[2020-11-11 15:51:07,264] {hiveserver2:265} INFO - Closing active operation\n",
      "[2020-11-11 15:51:07,282] {hive_server_hook:163} INFO - Done. Loaded a total of 1754472 rows.\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "SELECT order_sn as car_id,\n",
    "       brand_code,\n",
    "       brand_name,\n",
    "       series_code,\n",
    "       series_name,\n",
    "       model_code,\n",
    "       model_name,\n",
    "       cast(mileage/10000 AS DECIMAL(10,2)) AS mileage_std,\n",
    "       color AS color_name,\n",
    "       first_license_date as first_license_plate_date,\n",
    "       province_name,\n",
    "       city_name,\n",
    "       cast(real_pay_amount/10000 AS DECIMAL(10,2)) AS price,\n",
    "       date(pay_time) as pay_time,\n",
    "       age AS license_month,\n",
    "       residual,\n",
    "       datediff(\"2020-12-31 00:00:00\", pay_time) AS days,\n",
    "       cast(year(first_license_date) AS INT) AS license_year\n",
    "FROM db_data.mid_car_dfc_sale_order_flag_b\n",
    "WHERE flag = 0\n",
    "and trade_type !='B2B' \n",
    "and pay_time is not null\n",
    "and pay_time<=\"2020-11-02\"\n",
    "and province_name is not null\n",
    "and city_name is not null\n",
    "\"\"\"\n",
    "# 说明 load_data_from_hive 是我们自己改的从大禹取数的函数，不是官方读取函数。请自行选择\n",
    "dtype={'model_code':str}\n",
    "data= read_from_hive2('mid_car_dfc_purchase_order',sql,dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:52:36.876652Z",
     "start_time": "2020-03-23T09:52:36.248495Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "raw_data = copy.deepcopy(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T01:39:49.813885Z",
     "start_time": "2020-03-24T01:39:49.692080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32505"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 建模数据涉及车型 \n",
    "len(data.model_code.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T01:46:47.925854Z",
     "start_time": "2020-03-24T01:46:45.299520Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_id</th>\n",
       "      <th>brand_code</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>series_code</th>\n",
       "      <th>series_name</th>\n",
       "      <th>model_code</th>\n",
       "      <th>model_name</th>\n",
       "      <th>mileage_std</th>\n",
       "      <th>color_name</th>\n",
       "      <th>first_license_plate_date</th>\n",
       "      <th>province_name</th>\n",
       "      <th>city_name</th>\n",
       "      <th>price</th>\n",
       "      <th>pay_time</th>\n",
       "      <th>license_month</th>\n",
       "      <th>residual</th>\n",
       "      <th>days</th>\n",
       "      <th>license_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13643647</td>\n",
       "      <td>brand-49</td>\n",
       "      <td>丰田</td>\n",
       "      <td>series-1072</td>\n",
       "      <td>汉兰达</td>\n",
       "      <td>054186468</td>\n",
       "      <td>2013款  汉兰达  2.7L 两驱7座探索版</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-09-01</td>\n",
       "      <td>四川</td>\n",
       "      <td>成都</td>\n",
       "      <td>11.25</td>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>98</td>\n",
       "      <td>0.342153</td>\n",
       "      <td>66</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11455539</td>\n",
       "      <td>brand-49</td>\n",
       "      <td>丰田</td>\n",
       "      <td>series-1072</td>\n",
       "      <td>汉兰达</td>\n",
       "      <td>054186468</td>\n",
       "      <td>2013款  汉兰达  2.7L 两驱7座探索版</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>山西</td>\n",
       "      <td>太原</td>\n",
       "      <td>19.60</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>51</td>\n",
       "      <td>0.596107</td>\n",
       "      <td>914</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12306403</td>\n",
       "      <td>brand-49</td>\n",
       "      <td>丰田</td>\n",
       "      <td>series-1072</td>\n",
       "      <td>汉兰达</td>\n",
       "      <td>054186468</td>\n",
       "      <td>2013款  汉兰达  2.7L 两驱7座探索版</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>宁夏</td>\n",
       "      <td>固原</td>\n",
       "      <td>19.00</td>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>54</td>\n",
       "      <td>0.577859</td>\n",
       "      <td>577</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11434767</td>\n",
       "      <td>brand-49</td>\n",
       "      <td>丰田</td>\n",
       "      <td>series-1072</td>\n",
       "      <td>汉兰达</td>\n",
       "      <td>054186468</td>\n",
       "      <td>2013款  汉兰达  2.7L 两驱7座探索版</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>内蒙古</td>\n",
       "      <td>包头</td>\n",
       "      <td>18.80</td>\n",
       "      <td>2018-06-24</td>\n",
       "      <td>50</td>\n",
       "      <td>0.571776</td>\n",
       "      <td>921</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12286362</td>\n",
       "      <td>brand-49</td>\n",
       "      <td>丰田</td>\n",
       "      <td>series-1072</td>\n",
       "      <td>汉兰达</td>\n",
       "      <td>054186468</td>\n",
       "      <td>2013款  汉兰达  2.7L 两驱7座探索版</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>广东</td>\n",
       "      <td>湛江</td>\n",
       "      <td>18.30</td>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>65</td>\n",
       "      <td>0.556569</td>\n",
       "      <td>568</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     car_id brand_code brand_name  series_code series_name model_code  \\\n",
       "0  13643647   brand-49         丰田  series-1072         汉兰达  054186468   \n",
       "1  11455539   brand-49         丰田  series-1072         汉兰达  054186468   \n",
       "2  12306403   brand-49         丰田  series-1072         汉兰达  054186468   \n",
       "3  11434767   brand-49         丰田  series-1072         汉兰达  054186468   \n",
       "4  12286362   brand-49         丰田  series-1072         汉兰达  054186468   \n",
       "\n",
       "                 model_name  mileage_std color_name first_license_plate_date  \\\n",
       "0  2013款  汉兰达  2.7L 两驱7座探索版         12.0          3               2012-09-01   \n",
       "1  2013款  汉兰达  2.7L 两驱7座探索版          8.0          4               2014-05-01   \n",
       "2  2013款  汉兰达  2.7L 两驱7座探索版          5.5          3               2015-01-01   \n",
       "3  2013款  汉兰达  2.7L 两驱7座探索版          4.0          4               2014-05-01   \n",
       "4  2013款  汉兰达  2.7L 两驱7座探索版          9.0          3               2014-02-01   \n",
       "\n",
       "  province_name city_name  price    pay_time  license_month  residual  days  \\\n",
       "0            四川        成都  11.25  2020-10-26             98  0.342153    66   \n",
       "1            山西        太原  19.60  2018-07-01             51  0.596107   914   \n",
       "2            宁夏        固原  19.00  2019-06-03             54  0.577859   577   \n",
       "3           内蒙古        包头  18.80  2018-06-24             50  0.571776   921   \n",
       "4            广东        湛江  18.30  2019-06-12             65  0.556569   568   \n",
       "\n",
       "   license_year  \n",
       "0          2012  \n",
       "1          2014  \n",
       "2          2015  \n",
       "3          2014  \n",
       "4          2014  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['mileage_std'] = data['mileage_std'].astype('float')\n",
    "data['price'] = data['price'].astype('float')\n",
    "data['license_month'] = data['license_month'].astype('int')\n",
    "data['residual'] = data['residual'].astype('float')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T01:46:55.431358Z",
     "start_time": "2020-03-24T01:46:53.286886Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取 001 处理好的数据\n",
    "model = pd.read_csv(curr_dir+\"2020-11-02版车型参数及独热编码.csv\", header=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:08:37.217138Z",
     "start_time": "2020-03-23T09:08:37.211913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model_code', 'model_year', 'new_car_price', 'wheel_base', 'length',\n",
       "       'height', 'width', 'max_torque', 'max_power', 'engine_volume_l',\n",
       "       ...\n",
       "       'series_level53', 'series_level54', 'series_level55', 'series_level56',\n",
       "       'series_level57', 'series_level58', 'series_level59', 'series_level60',\n",
       "       'series_level61', 'series_level62'],\n",
       "      dtype='object', length=180)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T01:47:05.640819Z",
     "start_time": "2020-03-24T01:47:03.214503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并前数据数目为:1756087, 车型数量为：32505\n",
      "<---------------------------------------->\n",
      "合并后数据数目为:1751604, 车型数量为：31464\n"
     ]
    }
   ],
   "source": [
    "# 读取可估价的车型\n",
    "model = model[['model_code', 'model_year', 'new_car_price','year_1', 'year_2', 'year_3', 'year_4', 'year_5', 'year_6',\n",
    "                     'year_7', 'year_8', 'year_9', 'year_10', 'year_11', 'year_12', 'year_13', \n",
    "                     'year_14', 'year_15', 'year_16','rate','rate_count']]\n",
    "print(\"合并前数据数目为:%d, 车型数量为：%d\" % (data.shape[0], len(data['model_code'].unique())))\n",
    "data['model_code'] = data['model_code'].astype('str')\n",
    "data = pd.merge(data, model, on='model_code', how='inner')\n",
    "print(\"<---------------------------------------->\")\n",
    "print(\"合并后数据数目为:%d, 车型数量为：%d\" % (data.shape[0], len(data['model_code'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T01:38:49.343123Z",
     "start_time": "2020-03-24T01:38:49.119990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012款 五菱荣光小卡 1.2L 双排基本型                     129\n",
       "2011款 瑞风 2.4L政采版 手动豪华型                      117\n",
       "2014款 道奇Ram 长角号 5.7L 自动 美规版                 113\n",
       "2017款 道奇Ram 长角号 5.7L V8 美规版                  81\n",
       "2014款 道奇Ram 皮卡RAM1500 5.7L 自动                80\n",
       "2011款 瑞风 2.0L政采版 手动豪华型                       76\n",
       "2011款 瑞风 2.8T穿梭 柴油舒适版HFC4DA1-2B1             73\n",
       "2012款 五菱荣光小卡 1.5L 双排                         61\n",
       "2013款 金旅考斯特 XML6700                          51\n",
       "2012款 瑞风 1.9T穿梭 柴油舒适型HFC4DB1-2C              50\n",
       "2014款 坦途 5.7L TRD 美规版                        49\n",
       "2011款 HIACE 2.7L自动标准版13座                     46\n",
       "2014款 金杯海狮 2.0L舒适型V19                        44\n",
       "2014款 金杯海狮 2.0L豪华型V19                        40\n",
       "2007款 柯斯达 2.7L汽油豪华版 20座                      40\n",
       "2011款 经典全顺 柴油 短轴 多功能 中顶 6座                   39\n",
       "2011款 金杯海狮 2.0L第五代翔运舒适型4G20D4B               36\n",
       "2012款 长安星光4500 1.3L标准型4G13S1                 36\n",
       "2017款 上汽大通V80 2.5T5挡手动傲运通国V短轴中顶5/6/10座       35\n",
       "2012款 东风小康C37 1.4L豪华型                        31\n",
       "2009款 经典全顺 2.8T柴油标准型短轴中顶JX493ZLQ3            31\n",
       "2012款 瑞风 1.9T祥和 柴油长轴政采版HFC4DB1-2C            31\n",
       "2012款 五菱荣光小卡 1.2L 单排基本型                      30\n",
       "2013款 经典全顺 2.8T柴油普通型短轴中顶JX493ZLQ3A           28\n",
       "2012款 长安星光4500 1.3L基本型4G13S1                 25\n",
       "2017款 道奇Ram 皮卡REBEL(叛逆者)5.7L V8 美规版          25\n",
       "2011款 SAVANA 6.0L 商务之星10座                    24\n",
       "2011款 瑞风 2.8T穿梭 柴油标准版HFC4DA1-2B1             23\n",
       "2014款 坦途 5.7L 手自一体 白金版                       23\n",
       "2005款 HIACE 13人座豪华小客车 TRH223L—LEPNK 豪华版      22\n",
       "                                           ... \n",
       "2014款 御风 3.0T领尊版长轴高顶ZD30                      1\n",
       "2006款 都灵 A52                                  1\n",
       "2019款 五菱荣光 1.2L S 厢式运输车基本型5座                  1\n",
       "2016款 睿行M90 2.0L商务型4G94S                      1\n",
       "2018款 金杯T32 1.5L厢式PVC标准型DLCG14                1\n",
       "2009款 新世代全顺 2.4T柴油多功能型长轴高顶国III                1\n",
       "2014款 成功K1 1.2L 基本型                           1\n",
       "2009款 宝迪 3.0T-A39基本型高顶                        1\n",
       "2017款 上汽大通V80 2.5T5挡手动傲运通国IV短轴超低顶5/6/10座      1\n",
       "2015款 长安星卡 1.2L 双排 手动基本型                      1\n",
       "2014款 凌铃 1.0L短轴版双排LJ465Q-2AE                  1\n",
       "2014款 福瑞达 1.4L单排 标准型K14B-A                    1\n",
       "2018款 东风小康C31 1.2L标准型国V DK12                  1\n",
       "2009款 经典全顺 2.8T柴油豪华型长轴高顶JX493ZLQ3             1\n",
       "2014款 SAVANA 6.0L 2500S                       1\n",
       "2017款 上汽大通V80 2.5T6挡手动傲运通国V短轴超低顶5/6/10座       1\n",
       "2004款 金杯海狮 超级领航者SY6500B2C(H)                  1\n",
       "2011款 福田风景 2.8T快运标准型长轴版4JB1T                  1\n",
       "2014款 尊行 2.7L尊贵版                              1\n",
       "2011款 佳宝T51 1.0L基本型                           1\n",
       "2014款 上汽大通V80 2.5T傲运通长轴中顶                     1\n",
       "2018款 凯普特 K6-L轻卡 总宽2.55米 150马力载货车底盘           1\n",
       "2018款 海星T20 1.0L栏板2.5米标准型DL465Q5              1\n",
       "2006款 经典全顺 汽油长轴普通15座中顶                        1\n",
       "2016款 福田风景 2.0L风景快运版长轴高顶4Q20M1                1\n",
       "2015款 柯斯达 2.7L高级车TRB53L-ZCMSK 20座             1\n",
       "2014款 凯特 2.8T轻型客车豪华型SC28R                     1\n",
       "2019款 五菱之光小卡 1.2L 双排                          1\n",
       "2019款 神骐T20 1.5L T20L单排厢式DAM15KR 国VI          1\n",
       "2012款 阁瑞斯 2.5T智领 经典型(长轴)柴油DK4A                1\n",
       "Name: model_name, Length: 1039, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不能参加估计的车型查看 \n",
    "raw_data[~raw_data.model_code.isin(list(set(data.model_code)))]['model_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T01:47:10.432093Z",
     "start_time": "2020-03-24T01:47:10.422924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8430, 21)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[model['model_year']<=2005].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T01:47:33.721737Z",
     "start_time": "2020-03-24T01:47:26.957160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "增加限制后，数据数量为:1702828, 车型数量为:29430\n"
     ]
    }
   ],
   "source": [
    "# # 去掉一些不合理的数据 （meimei版）\n",
    "data_m = data[(data['mileage_std']>=0.01) & (data['mileage_std']<=50)]\n",
    "data_m = data_m[(data_m['price']>=0.3) & (data_m['price']<=300)]\n",
    "data_m = data_m[(data_m['license_month']>=1) & (data_m['license_month']<=180)]\n",
    "# data_m = data_m[(data_m['residual']>=0.05) & (data_m['residual']<1)]\n",
    "data_m = data_m[(data_m['model_year']>=2006)]\n",
    "data_m = data_m[data_m['license_year']>=2005]\n",
    "data_m = data_m[(data_m['new_car_price']>=1) & (data_m['new_car_price']<=500)]\n",
    "print(\"增加限制后，数据数量为:%d, 车型数量为:%d\" % (data_m.shape[0], len(data_m['model_code'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T01:48:16.023227Z",
     "start_time": "2020-03-24T01:48:13.936826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "增加限制后，数据数量为:1702803, 车型数量为:29427\n"
     ]
    }
   ],
   "source": [
    "#需要计算 meimei \n",
    "data_m['per_mile'] = round(data_m['mileage_std']/(data_m['license_month']/12),2)\n",
    "data_m['year_err'] = data_m['license_year'] - data_m['model_year']\n",
    "data_m = data_m[(data_m['year_err']>=-2) & (data_m['year_err']<=6)]\n",
    "print(\"增加限制后，数据数量为:%d, 车型数量为:%d\" % (data_m.shape[0], len(data_m['model_code'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T01:40:47.328545Z",
     "start_time": "2020-03-24T01:40:47.310710Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取编码完成的省份数据\n",
    "province = pd.read_csv(\"province_new.csv\", header=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T01:48:25.955858Z",
     "start_time": "2020-03-24T01:48:20.331950Z"
    }
   },
   "outputs": [],
   "source": [
    "data2m= pd.merge(data_m, province, how='left', on='province_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T03:33:14.876290Z",
     "start_time": "2020-03-24T01:51:11.891253Z"
    }
   },
   "outputs": [],
   "source": [
    "# 计算车辆当前保值率\n",
    "def computer_with_license_month(tar):\n",
    "    license_month = tar['license_month']\n",
    "    if(license_month<=12):\n",
    "        #tar['keep_value'] = tar['year_1']\n",
    "        return tar['year_1']\n",
    "    else:\n",
    "        year = license_month//12\n",
    "        #当前年保值率\n",
    "        keep_max = tar[\"year_\"+str(int(year))]\n",
    "        #下一年的保值率\n",
    "        keep_min = tar[\"year_\"+str(int(year+1))]\n",
    "        \n",
    "        #相比于上一年，已经过了几个月\n",
    "        mon = license_month-12*year\n",
    "        tem = (keep_max-keep_min)/12\n",
    "        \n",
    "        #tar['keep_value'] = round(keep_max - tem*mon, 4)\n",
    "        return round(keep_max - tem*mon, 4)\n",
    "\n",
    "#data2m = data2m.apply(computer_with_license_month, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====\n"
     ]
    }
   ],
   "source": [
    "data2m['keep_value'] = data2m[['license_month','year_1', 'year_2', 'year_3', 'year_4','year_5', 'year_6', 'year_7', 'year_8', 'year_9', 'year_10', 'year_11','year_12', 'year_13', 'year_14', 'year_15', 'year_16']].to_dict(orient='records')\n",
    "print(\"====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2m['keep_value'] = data2m['keep_value'].map(lambda tar:computer_with_license_month(tar))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T03:51:23.369559Z",
     "start_time": "2020-03-24T03:51:20.022871Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65250 entries, 0 to 65249\n",
      "Data columns (total 3 columns):\n",
      "model_code      65250 non-null object\n",
      "quality_mile    65250 non-null float64\n",
      "quality_year    65250 non-null float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data3m = data2m.drop(['year_1', 'year_2', 'year_3', 'year_4', \n",
    "                    'year_5', 'year_6', 'year_7', 'year_8', \n",
    "                    'year_9', 'year_10', 'year_11', 'year_12', \n",
    "                    'year_13', 'year_14', 'year_15', 'year_16'], axis=1)\n",
    "quality = pd.read_csv(curr_dir+\"2020-11-02版车型参数及独热编码.csv\", header=0, low_memory=False)\n",
    "quality = quality[['model_code', 'quality_mile', 'quality_year']]\n",
    "quality.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3m = pd.merge(data3m, quality, how='left', on='model_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T05:08:30.359687Z",
     "start_time": "2020-03-24T03:52:06.208109Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_quality(license_month,mileage_std,quality_mile,quality_year):\n",
    "    year = round(license_month/12, 2)\n",
    "    if mileage_std < quality_mile and year< quality_year:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "       \n",
    "data3m['quality'] = list(map(lambda license_month,mileage_std,quality_mile,quality_year:get_quality(license_month,mileage_std,quality_mile,quality_year),\n",
    "          data3m['license_month'],data3m['mileage_std'],data3m['quality_mile'],data3m['quality_year']))\n",
    "data3m = data3m.drop(['quality_mile', 'quality_year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-24T08:41:24.991884Z",
     "start_time": "2020-02-24T07:06:15.099273Z"
    }
   },
   "outputs": [],
   "source": [
    "#计算一下log  替换成 hive 计算  代码更新\n",
    "# math.log 效率太低了，换成 np.log 之前是直接在取数的时候换的，以下code 需要测试确认\n",
    "data3m['mile_log']=round(np.log2(data3m['mileage_std']), 4)\n",
    "data3m['license_month_log']=round(np.log2(data3m['license_month']), 4)\n",
    "data3m['new_car_price_log']=round(np.log2(data3m['new_car_price']), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征筛选2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T07:04:45.509916Z",
     "start_time": "2020-03-24T07:04:41.319389Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1701843, 60)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 根据per_mile过滤一下数据\n",
    "data3m = data3m[data3m['per_mile']<=10]\n",
    "data3m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T07:42:03.361215Z",
     "start_time": "2020-03-24T07:38:34.931868Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据筛选  查看每个车型对应的建模数据\n",
    "data_counts_mei = data3m.groupby('model_code')['car_id'].count().rename('count').reset_index()\n",
    "data5m = pd.merge(data3m, data_counts_mei, how='left', on='model_code')\n",
    "data5m = data5m.reset_index(drop=True)\n",
    "data5m.to_csv(curr_dir + \"2020-11-02版带count处理完成的零售数据m.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T07:45:55.106120Z",
     "start_time": "2020-03-24T07:45:54.860591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "交易条数超过5条的数据量是:1682754, 车型数量是:19969\n",
      "交易条数少于5条的数据量是:19089, 车型数量是:9442\n"
     ]
    }
   ],
   "source": [
    "# 之前测试了两种 数据，所以有两条记录。\n",
    "\n",
    "#交易条数超过5条\n",
    "datahm = data5m[data5m['count']>=5]\n",
    "#交易条数少于5条\n",
    "datalm = data5m[data5m['count']<5]\n",
    "\n",
    "print(\"交易条数超过5条的数据量是:%d, 车型数量是:%d\" % (datahm.shape[0], len(datahm['model_code'].unique())))\n",
    "print(\"交易条数少于5条的数据量是:%d, 车型数量是:%d\" % (datalm.shape[0], len(datalm['model_code'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T07:46:51.256649Z",
     "start_time": "2020-03-24T07:46:38.092907Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "单个model_code, 交易记录数超过5条, 使用\n",
    "StratifiedShuffleSplit来进行划分, 测试\n",
    "训练比例2:8; 单个model_code交易记录数少\n",
    "于5条, 手动划分\n",
    "\"\"\"\n",
    "#step1:首先划分数据量超过5条的\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "stratified = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T07:53:18.971319Z",
     "start_time": "2020-03-24T07:53:06.782430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1346203, 61)\n",
      "(336551, 61)\n"
     ]
    }
   ],
   "source": [
    "# 切meimei 的数据\n",
    "for sub_set1, sub_set2 in stratified.split(datahm, datahm['model_code']):\n",
    "    train_1m = datahm.iloc[sub_set1]\n",
    "    test_1m = datahm.iloc[sub_set2]\n",
    "print(train_1m.shape)\n",
    "print(test_1m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/souche/projects/calculation/py3dev_new/lib/python3.5/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "datalm['car_id'] = datalm['car_id'].map(lambda x:str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T08:09:03.278419Z",
     "start_time": "2020-03-24T08:04:28.951261Z"
    }
   },
   "outputs": [],
   "source": [
    "#按对应比例划分训练集和测试集\n",
    "# 根据上面的订单号 ，修改函数里面的划分 \n",
    "from sklearn.utils import shuffle\n",
    "def split_data(data):\n",
    "    model_code_list = list(data['model_code'].unique())\n",
    "    #用来保存抽取的训练数据\n",
    "    data_train = data[data['car_id']==\"11145073\"]\n",
    "    #用来保存抽取的测试数据\n",
    "    data_test = data[data['car_id']==\"11377087\"]\n",
    "    for i in range(len(model_code_list)):\n",
    "        model_code = model_code_list[i]\n",
    "        if model_code==\"14809-n\":\n",
    "            continue\n",
    "        data_tem = data[data['model_code']==model_code]\n",
    "        if(data_tem.shape[0]==1):\n",
    "            data_train = pd.concat([data_train, data_tem])\n",
    "        elif(data_tem.shape[0]==2):\n",
    "            data_tem_test = data_tem.iloc[0:1, :]\n",
    "            data_tem_train = data_tem.iloc[1:2, :]\n",
    "            data_test = pd.concat([data_test, data_tem_test])\n",
    "            data_train = pd.concat([data_train, data_tem_train])\n",
    "        #三条以上的数据才能划分训练集和测试集\n",
    "        else:\n",
    "            data_tem = shuffle(data_tem)\n",
    "            n = int(round(data_tem.shape[0]*0.2))\n",
    "            data_tem_test = data_tem.iloc[0:n, :]\n",
    "            data_tem_train = data_tem.iloc[n:, :]\n",
    "            \n",
    "            data_test = pd.concat([data_test, data_tem_test])\n",
    "            data_train = pd.concat([data_train, data_tem_train])\n",
    "        if(i%1000==0):\n",
    "            print(\"已完成%d个model_code数据集划分, 共%d个, 进度%.2f%%\" % \n",
    "                  (i, len(model_code_list), i/len(model_code_list)*100))\n",
    "    return data_train, data_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T08:26:52.740308Z",
     "start_time": "2020-03-24T08:23:09.896734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已完成0个model_code数据集划分, 共9442个, 进度0.00%\n",
      "已完成1000个model_code数据集划分, 共9442个, 进度10.59%\n",
      "已完成2000个model_code数据集划分, 共9442个, 进度21.18%\n",
      "已完成3000个model_code数据集划分, 共9442个, 进度31.77%\n",
      "已完成4000个model_code数据集划分, 共9442个, 进度42.36%\n",
      "已完成5000个model_code数据集划分, 共9442个, 进度52.95%\n",
      "已完成6000个model_code数据集划分, 共9442个, 进度63.55%\n",
      "已完成7000个model_code数据集划分, 共9442个, 进度74.14%\n",
      "已完成8000个model_code数据集划分, 共9442个, 进度84.73%\n",
      "已完成9000个model_code数据集划分, 共9442个, 进度95.32%\n"
     ]
    }
   ],
   "source": [
    "train_2m, test_2m = split_data(datalm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T08:27:00.784249Z",
     "start_time": "2020-03-24T08:27:00.778958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13725, 61)\n",
      "(5364, 61)\n"
     ]
    }
   ],
   "source": [
    "print(train_2m.shape)\n",
    "print(test_2m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T08:27:53.157904Z",
     "start_time": "2020-03-24T08:27:22.616149Z"
    }
   },
   "outputs": [],
   "source": [
    "data_trainm = pd.concat([train_1m, train_2m])\n",
    "data_trainm = data_trainm.reset_index(drop=True)\n",
    "\n",
    "data_testm = pd.concat([test_1m, test_2m])\n",
    "data_testm = data_testm.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T08:35:17.776263Z",
     "start_time": "2020-03-24T08:31:57.262954Z"
    }
   },
   "outputs": [],
   "source": [
    "# 输出 处理好的 训练集和测试集 \n",
    "data_trainm.to_csv(curr_dir+\"2020-11-02版零售数据data_train2.csv\", header=True, index=False)\n",
    "data_testm.to_csv(curr_dir+\"2020-11-02版零售数据data_test2.csv\", header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
