{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-02-03 16:19:41,836] {<ipython-input-8-1cbf1b0aa466>:114} INFO - 程序启动.............\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import requests\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dayu import settings\n",
    "from dayu.hooks.mysql_hook import MySqlHook\n",
    "import logging\n",
    "import datetime\n",
    "from logging.handlers import TimedRotatingFileHandler\n",
    "from logging.handlers import RotatingFileHandler\n",
    "from sklearn.externals import joblib\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "from dayu.hooks.oss_hook import OSSHook\n",
    "\n",
    "from dayu.hooks.hive_server_hook import HiveServerHook\n",
    "from dayu.hooks.hive_cli_hook import HiveCliHook\n",
    "\n",
    "import time\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import csv, math\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from dayu import settings\n",
    "import os \n",
    "\n",
    "\n",
    "def split_table_name(datain):\n",
    "    new_cols = []\n",
    "    for column in datain.columns:\n",
    "        if(len(column.split('.'))<2):\n",
    "            new_cols.append(column)\n",
    "        else:\n",
    "            new_cols.append(column.split('.')[1])\n",
    "\n",
    "    datain.columns = new_cols\n",
    "    return datain\n",
    "\n",
    "def read_from_hive2(output_file_name,insql,dtype):\n",
    "    filename = output_file_name\n",
    "    filepath = curr_dir+filename\n",
    "    hive = HiveServerHook(\"warehouse_hive\")\n",
    "    hive.to_csv(insql,filepath , delimiter=',',lineterminator='\\n', output_header=True)\n",
    "    outdata = pd.read_csv(filepath, header=0,dtype=dtype)\n",
    "    # 去除列名中带有的表名\n",
    "    outdata = split_table_name(outdata)\n",
    "    return outdata\n",
    "\n",
    "\"\"\"\n",
    "    自定义函数\n",
    "\"\"\"\n",
    "def date_time_sub(startTime,endTime,date_format):\n",
    "    try:\n",
    "        startTime= datetime.datetime.strptime(startTime,date_format)\n",
    "        endTime= datetime.datetime.strptime(endTime,date_format)\n",
    "        return (endTime - startTime).days\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def get_hive_data(hql):\n",
    "    with data_source.connect_hive(key) as conn:\n",
    "        # key 是数据源的key, 必须是分配到任务所在项目的数据源才能连上\n",
    "        # 使用with生成一个cursor, 用来执行语句\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(hql, parameters=None, verbose=False)\n",
    "            print(cursor.description)\n",
    "            column_list = []\n",
    "            for col in cursor.description:\n",
    "                if len(col[0].split('.')) == 2:\n",
    "                    column_list.append(col[0].split('.')[1])\n",
    "                else:\n",
    "                    column_list.append(col[0])\n",
    "\n",
    "            data_list = cursor.fetchall() # 获取所有执行结果\n",
    "            data_list = [d for d in data_list]\n",
    "\n",
    "    data_df = pd.DataFrame(data_list,columns=column_list)\n",
    "    return data_df\n",
    "## 数据结果评估\n",
    "def data3m_pinggu(data_df,col):\n",
    "    total = data_df.shape[0]\n",
    "    num_3 = data_df.loc[(data_df[col]>=-0.03 ) & (data_df[col]<=0.03 )].shape[0]\n",
    "    print(\"P<3%: \",round(num_3/total,4))\n",
    "    num_5 = data_df.loc[(data_df[col]>=-0.05 ) & (data_df[col]<=0.05 )].shape[0]\n",
    "    print(\"P<5%: \",round(num_5/total,4))\n",
    "    num_8 = data_df.loc[(data_df[col]>=-0.08 ) & (data_df[col]<=0.08 )].shape[0]\n",
    "    print(\"P<8%: \",round(num_8/total,4))\n",
    "    num_10 = data_df.loc[(data_df[col]>=-0.1 ) & (data_df[col]<=0.1 )].shape[0]\n",
    "    print(\"P<10%: \",round(num_10/total,4))\n",
    "    num_20 = data_df.loc[(data_df[col]>=-0.2 ) & (data_df[col]<=0.2 )].shape[0]\n",
    "    print(\"P<20%: \",round(num_20/total,4))\n",
    "\n",
    "class Logger:       \n",
    "    def __init__(self, logName, logFile):\n",
    "        self._logger = logging.getLogger(logName)\n",
    "        handler = logging.FileHandler(logFile)\n",
    "        formatter = logging.Formatter('%(asctime)s ********* %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        self._logger.addHandler(handler)\n",
    "        self._logger.setLevel(logging.INFO)\n",
    "\n",
    "    def log(self, msg):\n",
    "        if self._logger is not None:\n",
    "            self._logger.info(msg)\n",
    "\n",
    "curr_date = str(datetime.datetime.now())[0:10]\n",
    "pd.set_option('display.max_columns', 500)\n",
    "curr_dir = settings.TEMP_FILE_DIR+'/'\n",
    "hive_cli = HiveCliHook(\"warehouse_hive\")\n",
    "curr_dir = '/home/souche/qiongjiu/hgc/'\n",
    "\n",
    "logger = Logger('model_service','./log/accurate_valuation_cyp_run_log.log')\n",
    "logger.log(\"程序启动.............\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-02-03 16:16:09,908] {hiveserver2:138} INFO - Using database default as default\n",
      "[2021-02-03 16:16:10,048] {hive_server_hook:112} INFO - Running query: \n",
      "select * from db_data.enterprise2_car_parameter_onehot\n",
      "where ds = date_sub('2020-12-01',1) \n",
      "\n",
      "[2021-02-03 16:16:17,111] {hive_server_hook:162} INFO - Written 10000 rows so far.\n",
      "[2021-02-03 16:16:23,831] {hive_server_hook:162} INFO - Written 20000 rows so far.\n",
      "[2021-02-03 16:16:30,355] {hive_server_hook:162} INFO - Written 30000 rows so far.\n",
      "[2021-02-03 16:16:36,923] {hive_server_hook:162} INFO - Written 40000 rows so far.\n",
      "[2021-02-03 16:16:43,062] {hive_server_hook:162} INFO - Written 50000 rows so far.\n",
      "[2021-02-03 16:16:49,699] {hive_server_hook:162} INFO - Written 60000 rows so far.\n",
      "[2021-02-03 16:16:53,261] {hive_server_hook:162} INFO - Written 65632 rows so far.\n",
      "[2021-02-03 16:16:53,314] {hiveserver2:265} INFO - Closing active operation\n",
      "[2021-02-03 16:16:53,329] {hive_server_hook:163} INFO - Done. Loaded a total of 65632 rows.\n"
     ]
    }
   ],
   "source": [
    "hql = \"\"\"\n",
    "select * from db_data.enterprise2_car_parameter_onehot\n",
    "where ds = date_sub('2020-12-01',1) \n",
    "\"\"\"\n",
    "dtype={'city_code':str}\n",
    "car = read_from_hive2('model',hql,dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "car = car.drop(['driving_mode', 'gear_box_type', 'country_id',\n",
    "                'import_type', 'intake_type', 'fuel_form',\n",
    "                'year_1', 'year_2', 'year_3', 'year_4', 'year_5', 'year_6', 'year_7', 'year_8',\n",
    "                'year_9', 'year_10', 'year_11', 'year_12', 'year_13', 'year_14', 'year_15',\n",
    "                'year_16', 'car_body', 'rate', 'rate_count', 'series_level', 'level0',\n",
    "                'level1', 'level2','level3','level4','level5','level6','level7','level8'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-02-03 16:26:40,781] {oss_hook:28} INFO - Done. Loaded the key algorithm/qiongjiu/valuation/全网数据-优化模型/2021-02-03/enterprise2_car_parameter_onehot.csv .\n",
      "enterprise2_car_parameter_onehot 文件ok........\n",
      "[2021-02-03 16:26:56,393] {oss_hook:28} INFO - Done. Loaded the key algorithm/qiongjiu/valuation/全网数据-优化模型/2021-02-03/enterprise2_model_name_word2vec.csv .\n",
      "enterprise2_model_name_word2vec 文件ok........\n",
      "[2021-02-03 16:26:56,413] {hiveserver2:138} INFO - Using database default as default\n",
      "[2021-02-03 16:26:56,528] {hive_server_hook:112} INFO - Running query: \n",
      "select model_code,series_code,brand_code from db_data.ods_car_model_model \n",
      "where ds = date_sub('2021-02-02',1) \n",
      "\n",
      "[2021-02-03 16:26:56,903] {hive_server_hook:162} INFO - Written 10000 rows so far.\n",
      "[2021-02-03 16:26:57,076] {hive_server_hook:162} INFO - Written 20000 rows so far.\n",
      "[2021-02-03 16:26:57,248] {hive_server_hook:162} INFO - Written 30000 rows so far.\n",
      "[2021-02-03 16:26:57,421] {hive_server_hook:162} INFO - Written 40000 rows so far.\n",
      "[2021-02-03 16:26:57,579] {hive_server_hook:162} INFO - Written 50000 rows so far.\n",
      "[2021-02-03 16:26:57,744] {hive_server_hook:162} INFO - Written 60000 rows so far.\n",
      "[2021-02-03 16:26:57,911] {hive_server_hook:162} INFO - Written 70000 rows so far.\n",
      "[2021-02-03 16:26:57,964] {hive_server_hook:162} INFO - Written 73431 rows so far.\n",
      "[2021-02-03 16:26:57,967] {hiveserver2:265} INFO - Closing active operation\n",
      "[2021-02-03 16:26:57,977] {hive_server_hook:163} INFO - Done. Loaded a total of 73431 rows.\n",
      "[2021-02-03 16:26:59,821] {oss_hook:28} INFO - Done. Loaded the key algorithm/qiongjiu/valuation/全网数据-优化模型/2021-02-03/enterprise2_keep_value_and_rate.csv .\n",
      "enterprise2_keep_value_and_rate 文件ok........\n"
     ]
    }
   ],
   "source": [
    "# 导出车型参数及独热编码\n",
    "car_all = pd.read_csv(curr_dir+\"2021-02-02版车型参数及独热编码.csv\", header = 0, low_memory=False)\n",
    "car = car_all[['model_code', 'model_year', 'new_car_price', 'wheel_base', 'length', 'height', 'width', 'max_torque', 'max_power', 'engine_volume_l', 'cylinder_number', 'level', 'seat_number_top', 'quality_mile', 'quality_year', 'driving_mode0', 'driving_mode1', 'driving_mode2', 'driving_mode3', 'driving_mode4', 'driving_mode5', 'driving_mode6', 'driving_mode7', 'driving_mode8', 'driving_mode9', 'gear_box_type0', 'gear_box_type1', 'gear_box_type2', 'gear_box_type3', 'gear_box_type4', 'gear_box_type5', 'gear_box_type6', 'gear_box_type7', 'gear_box_type8', 'gear_box_type9', 'gear_box_type10', 'country_id0', 'country_id1', 'country_id2', 'country_id3', 'country_id4', 'country_id5', 'country_id6', 'country_id7', 'country_id8', 'country_id9', 'country_id10', 'country_id11', 'country_id12', 'country_id13', 'country_id14', 'import_type0', 'import_type1', 'intake_type0', 'intake_type1', 'intake_type2', 'intake_type3', 'intake_type4', 'intake_type5', 'intake_type6', 'intake_type7', 'fuel_form0', 'fuel_form1', 'fuel_form2', 'fuel_form3', 'fuel_form4', 'fuel_form5', 'fuel_form6', 'fuel_form7', 'fuel_form8', 'car_body0', 'car_body1', 'car_body2', 'car_body3', 'car_body4', 'car_body5', 'car_body6', 'car_body7', 'car_body8', 'car_body9', 'car_body10', 'car_body11', 'series_level0', 'series_level1', 'series_level2', 'series_level3', 'series_level4', 'series_level5', 'series_level6', 'series_level7', 'series_level8', 'series_level9', 'series_level10', 'series_level11', 'series_level12', 'series_level13', 'series_level14', 'series_level15', 'series_level16', 'series_level17', 'series_level18', 'series_level19', 'series_level20', 'series_level21', 'series_level22', 'series_level23', 'series_level24', 'series_level25', 'series_level26', 'series_level27', 'series_level28', 'series_level29', 'series_level30', 'series_level31', 'series_level32', 'series_level33', 'series_level34', 'series_level35', 'series_level36', 'series_level37', 'series_level38', 'series_level39', 'series_level40', 'series_level41', 'series_level42', 'series_level43', 'series_level44', 'series_level45', 'series_level46', 'series_level47', 'series_level48', 'series_level49', 'series_level50', 'series_level51', 'series_level52', 'series_level53', 'series_level54', 'series_level55', 'series_level56', 'series_level57', 'series_level58', 'series_level59', 'series_level60', 'series_level61', 'series_level62']]\n",
    "\n",
    "A=[\"Mini Bus\",'BUS']\n",
    "car.loc[car.level.isin(A), 'level'] = \"A\"\n",
    "ph = curr_dir+\"enterprise2_car_parameter_onehot.csv\"\n",
    "car.to_csv(ph)\n",
    "from dayu.hooks.oss_hook import OSSHook\n",
    "oss = OSSHook(\"oss_algorithm\")\n",
    "oss.put_file(\"algorithm/qiongjiu/valuation/全网数据-优化模型/\"+curr_date+\"/enterprise2_car_parameter_onehot.csv\", ph)\n",
    "print(\"enterprise2_car_parameter_onehot 文件ok........\")\n",
    "\n",
    "## 导出TF-IDF权重的词向量\n",
    "vec = pd.read_csv(curr_dir+\"2021-02-02版-TF-IDF权重的词向量.csv\", dtype={'model_code': str}, header = 0)\n",
    "ph = curr_dir+\"enterprise2_model_name_word2vec.csv\"\n",
    "vec.to_csv(ph)\n",
    "from dayu.hooks.oss_hook import OSSHook\n",
    "oss = OSSHook(\"oss_algorithm\")\n",
    "oss.put_file(\"algorithm/qiongjiu/valuation/全网数据-优化模型/\"+curr_date+\"/enterprise2_model_name_word2vec.csv\", ph)\n",
    "print(\"enterprise2_model_name_word2vec 文件ok........\")\n",
    "## 导出保值率和汽车之家评论数据\n",
    "hql = \"\"\"\n",
    "select model_code,series_code,brand_code from db_data.ods_car_model_model \n",
    "where ds = date_sub('2021-02-02',1) \n",
    "\"\"\"\n",
    "dtype={'city_code':str}\n",
    "model_info = read_from_hive2('model',hql,dtype)\n",
    "\n",
    "car_all = pd.merge(car_all, model_info,on='model_code',how='left')\n",
    "\n",
    "keep_value = car_all[['model_code', 'year_1', 'year_2', 'year_3', 'year_4', 'year_5', 'year_6', 'year_7', 'year_8',\n",
    "                         'year_9', 'year_10', 'year_11', 'year_12', 'year_13', 'year_14', 'year_15',\n",
    "                         'year_16', 'rate', 'rate_count','series_code','brand_code']]\n",
    "\n",
    "ph = curr_dir+\"enterprise2_keep_value_and_rate.csv\"\n",
    "keep_value.to_csv(ph)\n",
    "from dayu.hooks.oss_hook import OSSHook\n",
    "oss = OSSHook(\"oss_algorithm\")\n",
    "oss.put_file(\"algorithm/qiongjiu/valuation/全网数据-优化模型/\"+curr_date+\"/enterprise2_keep_value_and_rate.csv\", ph)\n",
    "print(\"enterprise2_keep_value_and_rate 文件ok........\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
